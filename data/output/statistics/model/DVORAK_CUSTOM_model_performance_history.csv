number_of_classes,image_height,image_width,sequence_length,random_state,model_type,output_layer_activation_function,loss_function,adam_optimizer_learning_rate,training_shuffle,max_training_epochs,batch_size,early_stopping,early_stopping_monitor,early_stopping_mode,early_stopping_patience,accuracy,macro_precision,macro_recall,macro_f1,weighted_precision,weighted_recall,weighted_f1,model_output_path,architecture_and_evaluation_output_path
4,224,224,20,42,HARM - videomae-base,softmax,categorical_crossentropy,5e-05,True,4,2,True,val_loss,min,20,0.9882352941176472,0.9897959183673468,0.9903846153846154,0.9898897058823528,0.9887154861944776,0.9882352941176472,0.9882425028835063,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_videomae-base_4_classes_lr_5e-05__epochs_4__batch_size_2_2024-05-08_08:36:52,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-08_08:36:52.log
4,224,224,20,42,HARM - videomae-base,softmax,categorical_crossentropy,5e-05,True,4,2,True,val_loss,min,20,0.9647058823529412,0.9723883572567784,0.9569842738205365,0.9634322099918431,0.9668847921943896,0.9647058823529412,0.9646282751247673,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_videomae-base_4_classes_lr_5e-05__epochs_4__batch_size_2_2024-05-09_22:20:39,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_22:20:39.log
4,224,224,20,42,HARM - timesformer-base-finetuned-k400,softmax,categorical_crossentropy,5e-05,True,4,2,True,val_loss,min,20,0.9610027855153204,0.9618560606060608,0.9615808162531464,0.9608045141133376,0.9630893897189162,0.9610027855153204,0.9609958832472352,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_timesformer-base-finetuned-k400_4_classes_lr_5e-05__epochs_4__batch_size_2_2024-05-08_07:48:33,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-08_07:48:33.log
4,224,224,20,42,HARM - timesformer-base-finetuned-k400,softmax,categorical_crossentropy,5e-05,True,4,2,True,val_loss,min,20,0.958217270194986,0.9594343959765758,0.9618619651204604,0.9598653259850332,0.9600517649243616,0.958217270194986,0.9582519085956042,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_timesformer-base-finetuned-k400_4_classes_lr_5e-05__epochs_4__batch_size_2_2024-05-07_21:59:37,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-07_21:59:37.log
4,224,224,20,42,HARM - timesformer-base-finetuned-k400,softmax,categorical_crossentropy,5e-05,True,4,2,True,val_loss,min,20,0.9526462395543176,0.9566666666666668,0.9603110391945344,0.9563753313120286,0.9572770366026486,0.9526462395543176,0.9525790780900047,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_timesformer-base-finetuned-k400_4_classes_lr_5e-05__epochs_4__batch_size_2_2024-05-07_20:02:46,
4,224,224,20,42,HARM - GoogLeNet,softmax,categorical_crossentropy,5e-05,True,25,2,True,val_loss,min,20,0.9434389140271492,0.944238624924083,0.9430290661448294,0.9428840065231976,0.9449783249873688,0.9434389140271492,0.943495988346201,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_googlenet_4_classes_adam_5e-05__epochs_25__batch_size_2__early_stopping_monitor_val_loss_mode_min_patience_20_2024-05-09_22:07:27.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_22:07:27.log
4,224,224,20,42,HARM - videomae-base,softmax,categorical_crossentropy,5e-05,True,4,2,True,val_loss,min,20,0.9294117647058824,0.9491525423728814,0.9241220735785952,0.9305720422161152,0.9437686939182454,0.9294117647058824,0.9302839901809088,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_videomae-base_4_classes_lr_5e-05__epochs_4__batch_size_2_2024-05-09_16:05:47,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_16:05:47.log
4,224,224,20,42,HARM - GoogLeNet,softmax,categorical_crossentropy,5e-05,True,25,2,True,val_loss,min,20,0.9298642533936652,0.9329878401087828,0.9315436551979284,0.9291724271882468,0.9360335335033464,0.9298642533936652,0.9299270857043512,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_googlenet_4_classes_adam_5e-05__epochs_25__batch_size_2__early_stopping_monitor_val_loss_mode_min_patience_20_2024-05-09_21:42:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_21:42:14.log
4,224,224,20,42,HARM - GoogLeNet,softmax,categorical_crossentropy,5e-05,True,25,2,True,val_loss,min,20,0.919683257918552,0.920536687107544,0.9199100779835272,0.9191772525203992,0.922516450950962,0.919683257918552,0.9200239584997876,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_googlenet_4_classes_adam_5e-05__epochs_25__batch_size_2__early_stopping_monitor_val_loss_mode_min_patience_20_2024-05-09_21:59:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_21:59:53.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.8461538461538461,0.8333333333333333,0.875,0.8035714285714286,0.9487179487179488,0.8461538461538461,0.8736263736263736,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_18:18:37.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_18:18:37.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.8461538461538461,0.9,0.875,0.8660714285714286,0.9076923076923078,0.8461538461538461,0.8543956043956045,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-09_07:43:57.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.8461538461538461,0.875,0.875,0.8660714285714286,0.8653846153846154,0.8461538461538461,0.8461538461538461,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:32:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.8461538461538461,0.9166666666666666,0.8333333333333334,0.825,0.8974358974358974,0.8461538461538461,0.823076923076923,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:40:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.7692307692307693,0.8375,0.75,0.7559523809523809,0.8307692307692308,0.7692307692307693,0.7701465201465201,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:13:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.7692307692307693,0.75,0.75,0.7410714285714286,0.7884615384615384,0.7692307692307693,0.7692307692307693,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_02:04:27.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.7692307692307693,0.8333333333333333,0.7291666666666666,0.7476190476190476,0.8205128205128205,0.7692307692307693,0.7663003663003664,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_08:49:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.7692307692307693,0.8166666666666667,0.8125,0.768452380952381,0.8564102564102564,0.7692307692307693,0.765018315018315,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-07_23:34:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.7692307692307693,0.7833333333333333,0.7916666666666666,0.7817460317460316,0.758974358974359,0.7692307692307693,0.7570207570207571,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:26:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.7692307692307693,0.85,0.75,0.7430555555555555,0.8461538461538461,0.7692307692307693,0.7542735042735043,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-07_07:27:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.7692307692307693,0.8928571428571428,0.8125,0.7818181818181817,0.868131868131868,0.7692307692307693,0.7314685314685314,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_18:07:30.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_17:59:59.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.6923076923076923,0.7666666666666666,0.7291666666666666,0.7321428571428572,0.758974358974359,0.6923076923076923,0.7087912087912088,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:18:09.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,25,0.6923076923076923,0.7916666666666666,0.7291666666666666,0.7428571428571429,0.7435897435897435,0.6923076923076923,0.6989010989010989,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:12:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.6923076923076923,0.75,0.6875,0.6916666666666667,0.7692307692307693,0.6923076923076923,0.6974358974358974,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:21:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.6923076923076923,0.7499999999999999,0.75,0.6583333333333332,0.846153846153846,0.6923076923076923,0.6948717948717948,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_18:03:43.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_17:59:59.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.6923076923076923,0.8125,0.6875,0.6874999999999999,0.8076923076923077,0.6923076923076923,0.6923076923076923,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-03_19:49:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_19:49:06.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.6923076923076923,0.7291666666666666,0.7291666666666666,0.6970238095238095,0.7564102564102563,0.6923076923076923,0.6908424908424908,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-07_07:21:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.6923076923076923,0.6916666666666667,0.6875,0.6696428571428571,0.7282051282051282,0.6923076923076923,0.6895604395604396,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-09_07:39:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.6923076923076923,0.7916666666666666,0.75,0.7,0.8333333333333333,0.6923076923076923,0.6871794871794872,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-07_07:19:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.6923076923076923,0.7125,0.6875,0.6666666666666666,0.7538461538461539,0.6923076923076923,0.6858974358974359,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:23:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.6923076923076923,0.7083333333333333,0.75,0.7023809523809523,0.7179487179487178,0.6923076923076923,0.684981684981685,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-05_21:14:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.6923076923076923,0.6875,0.7291666666666666,0.6970238095238095,0.6923076923076923,0.6923076923076923,0.6835164835164835,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:27:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.6923076923076923,0.6666666666666666,0.6875,0.6696428571428571,0.6858974358974359,0.6923076923076923,0.6813186813186813,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_21:16:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.6923076923076923,0.7,0.7083333333333334,0.6984126984126984,0.6820512820512821,0.6923076923076923,0.6800976800976801,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:56:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.6923076923076923,0.7083333333333333,0.75,0.6761904761904762,0.7564102564102563,0.6923076923076923,0.6783882783882784,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_17:59:59.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_17:59:59.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.6923076923076923,0.7083333333333333,0.75,0.6761904761904762,0.7564102564102563,0.6923076923076923,0.6783882783882784,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_18:12:29.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_17:59:59.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.6923076923076923,0.725,0.6458333333333333,0.6555555555555554,0.7,0.6923076923076923,0.6735042735042734,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:57:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.6923076923076923,0.725,0.6458333333333333,0.6555555555555554,0.7,0.6923076923076923,0.6735042735042734,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:13:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.6923076923076923,0.7916666666666666,0.75,0.6809523809523809,0.8333333333333333,0.6923076923076923,0.6637362637362637,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_08:56:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,128,128,20,42,HARM - ResNet,softmax,categorical_crossentropy,0.0001,True,200,4,True,val_loss,min,20,0.6444444444444445,0.6640989729225023,0.6369047619047619,0.6451612903225806,0.6684095860566449,0.6444444444444445,0.6504864311315924,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_resnet_4_classes_adam_0_0001__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_20_2024-05-09_13:31:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_13:31:48.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.6153846153846154,0.6833333333333333,0.6458333333333334,0.6587301587301588,0.6615384615384615,0.6153846153846154,0.6312576312576312,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:31:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.6153846153846154,0.75,0.6041666666666666,0.6261904761904762,0.7307692307692307,0.6153846153846154,0.6241758241758242,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_08:52:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.6923076923076923,0.625,0.6875,0.6309523809523809,0.6153846153846154,0.6923076923076923,0.6227106227106227,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:19:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.6153846153846154,0.6041666666666666,0.6041666666666666,0.5970238095238094,0.641025641025641,0.6153846153846154,0.621978021978022,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:26:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,False,val_loss,min,5,0.6153846153846154,0.6416666666666666,0.625,0.628968253968254,0.6358974358974359,0.6153846153846154,0.6202686202686203,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4_2024-04-05_21:09:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,False,val_loss,min,5,0.6153846153846154,0.6416666666666666,0.625,0.628968253968254,0.6358974358974359,0.6153846153846154,0.6202686202686203,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4_2024-04-05_21:19:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.6153846153846154,0.6833333333333332,0.6666666666666666,0.6345238095238095,0.7076923076923076,0.6153846153846154,0.6194139194139194,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_02:01:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.6153846153846154,0.6833333333333332,0.6666666666666666,0.6345238095238095,0.7076923076923076,0.6153846153846154,0.6194139194139194,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-09_07:48:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.6153846153846154,0.6625,0.625,0.617063492063492,0.6807692307692308,0.6153846153846154,0.6166056166056166,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-07_23:24:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.6153846153846154,0.6666666666666666,0.6666666666666666,0.65,0.641025641025641,0.6153846153846154,0.6153846153846154,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-05_21:17:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.6153846153846154,0.6916666666666667,0.6041666666666666,0.6190476190476191,0.658974358974359,0.6153846153846154,0.6153846153846154,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_02:03:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.6153846153846154,0.6041666666666666,0.6041666666666666,0.5982142857142857,0.6282051282051282,0.6153846153846154,0.6153846153846154,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-07_07:25:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.6153846153846154,0.6666666666666666,0.625,0.6011904761904762,0.7051282051282051,0.6153846153846154,0.6117216117216118,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-07_07:10:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.6153846153846154,0.6666666666666666,0.625,0.6011904761904762,0.7051282051282051,0.6153846153846154,0.6117216117216118,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-07_23:26:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.6153846153846154,0.6666666666666666,0.625,0.6011904761904762,0.7051282051282051,0.6153846153846154,0.6117216117216118,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-09_07:46:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.6153846153846154,0.6083333333333333,0.6041666666666666,0.601190476190476,0.6205128205128205,0.6153846153846154,0.6117216117216117,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_21:14:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.6153846153846154,0.6583333333333333,0.5833333333333333,0.5972222222222221,0.6307692307692307,0.6153846153846154,0.6068376068376068,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:53:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.6153846153846154,0.625,0.6666666666666666,0.6345238095238095,0.6153846153846154,0.6153846153846154,0.6065934065934067,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-05_21:18:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.6153846153846154,0.65,0.6458333333333333,0.6,0.6846153846153846,0.6153846153846154,0.6051282051282052,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:22:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.6153846153846154,0.65,0.6458333333333333,0.6,0.6846153846153846,0.6153846153846154,0.6051282051282052,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:41:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.6153846153846154,0.65,0.6458333333333334,0.6416666666666666,0.6076923076923078,0.6153846153846154,0.6051282051282051,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:16:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,128,128,20,42,HARM - ResNet,softmax,categorical_crossentropy,0.0001,True,200,4,True,val_loss,min,20,0.6,0.6068181818181818,0.6160714285714286,0.5991982845529756,0.626902356902357,0.6,0.6045969286243885,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_resnet_4_classes_adam_0_0001__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_20_2024-05-09_13:21:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_13:21:46.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.6153846153846154,0.6458333333333334,0.6666666666666666,0.6517857142857142,0.6025641025641025,0.6153846153846154,0.6043956043956045,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:20:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.6153846153846154,0.6041666666666666,0.625,0.6071428571428572,0.6089743589743589,0.6153846153846154,0.6043956043956044,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-05_21:29:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.6153846153846154,0.675,0.5833333333333333,0.5833333333333333,0.676923076923077,0.6153846153846154,0.6025641025641024,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_02:07:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.6153846153846154,0.6041666666666666,0.6458333333333333,0.5970238095238095,0.6282051282051282,0.6153846153846154,0.6014652014652014,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_08:48:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.6153846153846154,0.7916666666666666,0.5833333333333333,0.6011904761904762,0.7435897435897435,0.6153846153846154,0.5989010989010989,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:16:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.6153846153846154,0.6083333333333333,0.6458333333333334,0.6095238095238096,0.6076923076923078,0.6153846153846154,0.5963369963369963,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:44:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.6153846153846154,0.5875,0.6875,0.6041666666666666,0.6076923076923078,0.6153846153846154,0.5897435897435896,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_18:27:35.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_18:18:37.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.6153846153846154,0.6708333333333334,0.625,0.5809523809523809,0.7166666666666667,0.6153846153846154,0.5875457875457875,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:18:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.6153846153846154,0.775,0.625,0.6,0.7615384615384616,0.6153846153846154,0.5846153846153845,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:24:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.6153846153846154,0.5875,0.625,0.5833333333333333,0.6,0.6153846153846154,0.5833333333333333,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-09_07:52:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,128,128,20,42,HARM - ResNet,softmax,categorical_crossentropy,0.0001,True,200,4,True,val_loss,min,20,0.5777777777777777,0.5808531746031746,0.6011904761904762,0.5830546265328873,0.5748236331569665,0.5777777777777777,0.5671745323919236,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_resnet_4_classes_adam_0_0001__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_20_2024-05-09_13:40:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-05-09_13:40:07.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.5384615384615384,0.6666666666666666,0.5208333333333333,0.5392857142857143,0.6923076923076923,0.5384615384615384,0.5637362637362637,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:55:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,False,val_loss,min,5,0.5384615384615384,0.625,0.5416666666666666,0.5678571428571428,0.6153846153846154,0.5384615384615384,0.5604395604395604,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8_2024-04-05_21:11:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.6153846153846154,0.4553571428571428,0.5,0.4526515151515151,0.5604395604395604,0.6153846153846154,0.5571095571095571,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_18:23:37.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_18:18:37.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,False,val_loss,min,5,0.5384615384615384,0.6,0.5416666666666666,0.5611111111111111,0.5846153846153845,0.5384615384615384,0.5521367521367522,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16_2024-04-05_21:13:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.5384615384615384,0.6041666666666666,0.5833333333333333,0.5630952380952381,0.6217948717948717,0.5384615384615384,0.5479853479853479,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:23:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.5384615384615384,0.7333333333333334,0.5208333333333333,0.5583333333333333,0.6717948717948719,0.5384615384615384,0.5461538461538461,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:45:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.5384615384615384,0.6666666666666666,0.5833333333333333,0.5357142857142857,0.6923076923076923,0.5384615384615384,0.5439560439560439,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:15:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.5384615384615384,0.5583333333333332,0.5416666666666666,0.5357142857142857,0.5794871794871794,0.5384615384615384,0.5439560439560439,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:47:25.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.5384615384615384,0.5583333333333332,0.5416666666666666,0.5357142857142857,0.5794871794871794,0.5384615384615384,0.5439560439560439,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-09_07:54:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,False,val_loss,min,5,0.5384615384615384,0.5583333333333333,0.5416666666666666,0.5456349206349207,0.5589743589743589,0.5384615384615384,0.5433455433455433,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8_2024-04-05_21:22:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.5384615384615384,0.6071428571428572,0.5208333333333333,0.528030303030303,0.631868131868132,0.5384615384615384,0.5421911421911422,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:35:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.5384615384615384,0.5833333333333333,0.5625,0.5357142857142857,0.6217948717948717,0.5384615384615384,0.5421245421245421,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-09_07:50:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.5384615384615384,0.6458333333333334,0.5416666666666666,0.548611111111111,0.6153846153846154,0.5384615384615384,0.5384615384615384,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_08:51:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.5384615384615384,0.5,0.5,0.4910714285714286,0.5576923076923077,0.5384615384615384,0.5384615384615384,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-07_07:17:02.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.5384615384615384,0.5416666666666666,0.5416666666666666,0.5357142857142857,0.5512820512820512,0.5384615384615384,0.5384615384615384,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-07_23:30:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,35,0.5384615384615384,0.625,0.5208333333333333,0.5444444444444445,0.5769230769230769,0.5384615384615384,0.5367521367521367,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:23:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.5384615384615384,0.6488095238095238,0.5208333333333333,0.5292207792207793,0.6446886446886447,0.5384615384615384,0.535964035964036,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_02:06:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.5384615384615384,0.525,0.5208333333333333,0.5178571428571428,0.5435897435897435,0.5384615384615384,0.5347985347985348,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:01:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.5384615384615384,0.625,0.5208333333333333,0.525,0.6153846153846154,0.5384615384615384,0.5307692307692308,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:28:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.5384615384615384,0.5416666666666666,0.5208333333333333,0.5178571428571428,0.5512820512820512,0.5384615384615384,0.5296703296703297,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:53:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.5384615384615384,0.5416666666666666,0.5208333333333333,0.5178571428571428,0.5512820512820512,0.5384615384615384,0.5296703296703297,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:27:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.5384615384615384,0.5416666666666666,0.5833333333333333,0.5511904761904762,0.5384615384615384,0.5384615384615384,0.5296703296703297,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-07_23:33:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.6153846153846154,0.4761904761904761,0.6875,0.5211038961038961,0.5091575091575091,0.6153846153846154,0.525974025974026,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-10_21:11:22.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-10_21:03:31.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.5384615384615384,0.625,0.5833333333333333,0.5416666666666666,0.6153846153846154,0.5384615384615384,0.5256410256410257,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_20_2024-04-02_20:06:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_20:06:54.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.5384615384615384,0.625,0.5833333333333333,0.5416666666666666,0.6153846153846154,0.5384615384615384,0.5256410256410257,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:16:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.5384615384615384,0.625,0.5416666666666666,0.5166666666666666,0.6666666666666666,0.5384615384615384,0.5230769230769231,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:18:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.5384615384615384,0.5833333333333334,0.5833333333333334,0.5714285714285714,0.5256410256410257,0.5384615384615384,0.5186813186813187,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:14:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.5384615384615384,0.7166666666666667,0.625,0.4833333333333333,0.8358974358974358,0.5384615384615384,0.517948717948718,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-15_18:34:45.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-15_18:18:37.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,15,0.5384615384615384,0.525,0.5416666666666666,0.5178571428571428,0.5307692307692308,0.5384615384615384,0.5164835164835164,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-04_07:07:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-04_07:07:55.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.5384615384615384,0.525,0.5625,0.5267857142857143,0.5230769230769231,0.5384615384615384,0.5137362637362638,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_08:45:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,False,val_loss,min,5,0.5384615384615384,0.625,0.6041666666666666,0.5345238095238095,0.6538461538461539,0.5384615384615384,0.5113553113553113,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16_2024-04-05_21:23:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.5384615384615384,0.5249999999999999,0.5833333333333334,0.5333333333333333,0.517948717948718,0.5384615384615384,0.5076923076923077,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:35:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.6153846153846154,0.5416666666666666,0.625,0.5333333333333333,0.4743589743589743,0.6153846153846154,0.5025641025641026,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:54:25.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.5384615384615384,0.625,0.5833333333333334,0.5166666666666666,0.6538461538461539,0.5384615384615384,0.5025641025641026,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:41:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.5384615384615384,0.7321428571428572,0.625,0.5166666666666666,0.7912087912087912,0.5384615384615384,0.4871794871794872,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:31:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.4615384615384615,0.5791666666666666,0.4583333333333333,0.492063492063492,0.5397435897435897,0.4615384615384615,0.481074481074481,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:04:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.4615384615384615,0.4791666666666666,0.4583333333333333,0.4642857142857142,0.4935897435897435,0.4615384615384615,0.4725274725274725,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-02_19:17:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_19:17:10.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.4615384615384615,0.4791666666666666,0.4583333333333333,0.4642857142857143,0.4935897435897435,0.4615384615384615,0.4725274725274725,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:08:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.4615384615384615,0.5833333333333333,0.4583333333333333,0.475,0.5641025641025641,0.4615384615384615,0.4692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-05_21:26:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.4615384615384615,0.575,0.4583333333333333,0.4888888888888889,0.5153846153846153,0.4615384615384615,0.4683760683760684,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-07_23:29:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.4615384615384615,0.4583333333333333,0.4583333333333333,0.4511904761904762,0.4871794871794871,0.4615384615384615,0.4681318681318681,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_21:24:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.4615384615384615,0.55,0.5208333333333333,0.5208333333333334,0.5076923076923077,0.4615384615384615,0.4679487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:54:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.4615384615384615,0.4583333333333333,0.4583333333333333,0.4553571428571428,0.4679487179487179,0.4615384615384615,0.4615384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_30_2024-04-03_19:04:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_19:04:29.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.4615384615384615,0.4791666666666666,0.4791666666666666,0.4791666666666666,0.4615384615384615,0.4615384615384615,0.4615384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-07_23:27:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.4615384615384615,0.4791666666666666,0.4791666666666666,0.4732142857142857,0.4743589743589743,0.4615384615384615,0.4615384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_08:54:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.4615384615384615,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4615384615384615,0.4615384615384615,0.4615384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:01:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.4615384615384615,0.475,0.4583333333333333,0.4611111111111111,0.4692307692307692,0.4615384615384615,0.4598290598290598,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:30:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.4615384615384615,0.4999999999999999,0.4791666666666666,0.4623015873015872,0.5128205128205128,0.4615384615384615,0.4578754578754578,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:27:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.4615384615384615,0.5,0.4791666666666666,0.4623015873015872,0.5128205128205128,0.4615384615384615,0.4578754578754578,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_21:20:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.4615384615384615,0.5833333333333333,0.4791666666666666,0.4611111111111111,0.6153846153846154,0.4615384615384615,0.4564102564102564,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_21:26:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.4615384615384615,0.5625,0.4583333333333333,0.4791666666666666,0.5,0.4615384615384615,0.4564102564102564,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:17:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.4615384615384615,0.5625,0.4583333333333333,0.4791666666666666,0.5,0.4615384615384615,0.4564102564102564,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:03:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.4615384615384615,0.475,0.4791666666666666,0.4511904761904762,0.5025641025641026,0.4615384615384615,0.4553113553113553,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:50:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.4615384615384615,0.5583333333333333,0.4791666666666666,0.4499999999999999,0.6051282051282052,0.4615384615384615,0.4538461538461539,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:51:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.5384615384615384,0.4583333333333333,0.625,0.5095238095238095,0.4230769230769231,0.5384615384615384,0.4527472527472528,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:49:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.4615384615384615,0.4791666666666666,0.5208333333333333,0.4886904761904762,0.4615384615384615,0.4615384615384615,0.4527472527472528,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:07:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,30,0.4615384615384615,0.5654761904761905,0.4583333333333333,0.4744588744588743,0.5036630036630036,0.4615384615384615,0.4506160506160505,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:23:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.4615384615384615,0.4583333333333333,0.4791666666666666,0.4642857142857143,0.4487179487179487,0.4615384615384615,0.4505494505494505,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_02:02:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.4615384615384615,0.5833333333333334,0.5208333333333333,0.4964285714285714,0.5384615384615384,0.4615384615384615,0.4494505494505495,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:47:25.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.4615384615384615,0.475,0.4791666666666666,0.4583333333333333,0.4769230769230769,0.4615384615384615,0.4487179487179487,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_21:11:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.4615384615384615,0.4791666666666666,0.5208333333333333,0.4642857142857142,0.4935897435897435,0.4615384615384615,0.4468864468864468,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:28:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.5384615384615384,0.5071428571428571,0.5625,0.4833333333333333,0.4373626373626373,0.5384615384615384,0.4461538461538461,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:29:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.4615384615384615,0.5625,0.5416666666666666,0.5075757575757576,0.5192307692307693,0.4615384615384615,0.4428904428904428,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:26:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,30,0.4615384615384615,0.575,0.5208333333333333,0.4623015873015872,0.5692307692307692,0.4615384615384615,0.4426129426129426,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:21:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.4615384615384615,0.575,0.5208333333333333,0.4539682539682539,0.6076923076923078,0.4615384615384615,0.44004884004884,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:04:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.5384615384615384,0.4166666666666666,0.6041666666666666,0.4928571428571428,0.3717948717948717,0.5384615384615384,0.4395604395604395,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:02:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.4615384615384615,0.5833333333333333,0.5416666666666666,0.4825396825396826,0.5897435897435896,0.4615384615384615,0.4366300366300366,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:52:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.4615384615384615,0.4583333333333333,0.5208333333333333,0.463095238095238,0.4487179487179487,0.4615384615384615,0.4366300366300366,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:28:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.4615384615384615,0.4041666666666666,0.5208333333333334,0.45,0.3794871794871795,0.4615384615384615,0.4115384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:49:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.4615384615384615,0.3958333333333333,0.4791666666666666,0.4236111111111111,0.3846153846153846,0.4615384615384615,0.4102564102564102,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:54:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.3846153846153846,0.5416666666666667,0.3958333333333333,0.4305555555555556,0.5,0.3846153846153846,0.4102564102564102,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:23:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.4615384615384615,0.4166666666666666,0.5208333333333334,0.4499999999999999,0.3717948717948717,0.4615384615384615,0.4,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:47:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.4615384615384615,0.4166666666666666,0.5416666666666666,0.4666666666666667,0.3589743589743589,0.4615384615384615,0.4,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_02:05:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.3846153846153846,0.5,0.3958333333333333,0.425595238095238,0.4423076923076923,0.3846153846153846,0.3992673992673992,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_21:18:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.4615384615384615,0.375,0.4791666666666666,0.4166666666666666,0.3538461538461538,0.4615384615384615,0.3974358974358974,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:42:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.3846153846153846,0.5297619047619047,0.3958333333333333,0.4242424242424242,0.4725274725274725,0.3846153846153846,0.3939393939393939,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:26:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3846153846153846,0.425,0.3958333333333333,0.4055555555555555,0.4076923076923077,0.3846153846153846,0.3914529914529914,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-05_21:16:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.3846153846153846,0.425,0.3958333333333333,0.4055555555555555,0.4076923076923077,0.3846153846153846,0.3914529914529914,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-07_23:31:57.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3846153846153846,0.3958333333333333,0.3958333333333333,0.3928571428571428,0.391025641025641,0.3846153846153846,0.3846153846153846,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-09_07:41:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.3846153846153846,0.4166666666666666,0.3958333333333333,0.3964285714285714,0.3974358974358974,0.3846153846153846,0.3802197802197802,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:40:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3846153846153846,0.4166666666666666,0.3958333333333333,0.3916666666666666,0.4102564102564102,0.3846153846153846,0.3794871794871795,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:26:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3846153846153846,0.4625,0.3958333333333333,0.4047619047619047,0.3961538461538462,0.3846153846153846,0.3736263736263736,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:57:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.4615384615384615,0.4428571428571428,0.5625,0.3651515151515151,0.4989010989010989,0.4615384615384615,0.3724941724941725,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-10_21:07:05.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-10_21:03:31.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.4615384615384615,0.4428571428571428,0.5625,0.3651515151515151,0.4989010989010989,0.4615384615384615,0.3724941724941725,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-10_21:03:31.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-10_21:03:31.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3846153846153846,0.55,0.4583333333333333,0.375,0.5692307692307692,0.3846153846153846,0.3717948717948717,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:25:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.3846153846153846,0.4166666666666666,0.4166666666666666,0.3908730158730158,0.4102564102564102,0.3846153846153846,0.3699633699633699,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_08:57:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,35,0.4615384615384615,0.3854166666666666,0.5208333333333334,0.425,0.3333333333333333,0.4615384615384615,0.3692307692307693,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:21:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.4615384615384615,0.3854166666666666,0.5208333333333333,0.425,0.3333333333333333,0.4615384615384615,0.3692307692307693,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:50:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.3846153846153846,0.3541666666666666,0.375,0.3625,0.3589743589743589,0.3846153846153846,0.3692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-05_21:25:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.3846153846153846,0.4166666666666666,0.4166666666666666,0.3777777777777777,0.4358974358974358,0.3846153846153846,0.3692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:56:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.4615384615384615,0.35,0.5208333333333333,0.3928571428571428,0.3307692307692307,0.4615384615384615,0.3648351648351648,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:25:27.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.4615384615384615,0.35,0.5208333333333333,0.3928571428571428,0.3307692307692307,0.4615384615384615,0.3648351648351648,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:06:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.4615384615384615,0.5,0.5625,0.425,0.4871794871794871,0.4615384615384615,0.3615384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:15:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.4615384615384615,0.3333333333333333,0.4583333333333333,0.3749999999999999,0.3076923076923077,0.4615384615384615,0.3589743589743589,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:55:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.3846153846153846,0.3583333333333333,0.3958333333333333,0.3749999999999999,0.3384615384615385,0.3846153846153846,0.3589743589743589,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:52:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.4615384615384615,0.3611111111111111,0.4583333333333333,0.3788461538461538,0.329059829059829,0.4615384615384615,0.3585798816568047,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:29:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.3846153846153846,0.3375,0.375,0.3333333333333333,0.3692307692307692,0.3846153846153846,0.3525641025641025,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256_2024-04-07_07:30:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,15,0.3846153846153846,0.4722222222222222,0.4583333333333333,0.3587662337662337,0.4700854700854701,0.3846153846153846,0.3471528471528471,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:27:27.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.3846153846153846,0.4722222222222222,0.4583333333333333,0.3587662337662337,0.4700854700854701,0.3846153846153846,0.3471528471528471,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:43:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,25,0.3076923076923077,0.4666666666666666,0.3333333333333333,0.3720238095238095,0.4051282051282051,0.3076923076923077,0.336080586080586,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:23:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3846153846153846,0.3166666666666666,0.5,0.3214285714285714,0.3512820512820512,0.3846153846153846,0.3296703296703296,/home/peter/dp/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-10_21:16:46.keras,/home/peter/dp/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-10_21:03:31.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.3846153846153846,0.3333333333333333,0.4583333333333333,0.3511904761904761,0.3333333333333333,0.3846153846153846,0.3296703296703296,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:49:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.3076923076923077,0.375,0.3125,0.3166666666666666,0.4102564102564102,0.3076923076923077,0.3282051282051282,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128_2024-04-05_21:28:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3846153846153846,0.3125,0.3958333333333333,0.3464285714285714,0.2884615384615384,0.3846153846153846,0.3274725274725275,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:51:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3846153846153846,0.3333333333333333,0.4583333333333333,0.35,0.3205128205128205,0.3846153846153846,0.3230769230769231,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:32:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.3846153846153846,0.2916666666666666,0.3958333333333333,0.3333333333333333,0.282051282051282,0.3846153846153846,0.3230769230769231,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_21:22:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3846153846153846,0.3154761904761904,0.3958333333333333,0.3363636363636363,0.2985347985347985,0.3846153846153846,0.3216783216783216,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:55:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.3846153846153846,0.4375,0.4583333333333333,0.375,0.3846153846153846,0.3846153846153846,0.3205128205128205,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:47:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.3076923076923077,0.3541666666666666,0.3333333333333333,0.3261904761904762,0.3589743589743589,0.3076923076923077,0.3194139194139194,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_01:59:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.3846153846153846,0.3083333333333333,0.4583333333333333,0.3511904761904761,0.2923076923076922,0.3846153846153846,0.3186813186813186,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:56:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.3846153846153846,0.325,0.4583333333333333,0.3539682539682539,0.3,0.3846153846153846,0.3169719169719169,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:15:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3846153846153846,0.3214285714285714,0.4583333333333333,0.3361111111111111,0.3131868131868132,0.3846153846153846,0.3145299145299145,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:23:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.3846153846153846,0.3214285714285714,0.4791666666666666,0.3492063492063492,0.3003663003663003,0.3846153846153846,0.3101343101343101,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:07:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.3846153846153846,0.3333333333333333,0.4791666666666666,0.3611111111111111,0.3076923076923077,0.3846153846153846,0.3076923076923077,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:13:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3076923076923077,0.2708333333333333,0.2708333333333333,0.2708333333333333,0.3076923076923077,0.3076923076923077,0.3076923076923077,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64_2024-04-07_07:14:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3076923076923077,0.4,0.3125,0.3333333333333333,0.3384615384615385,0.3076923076923077,0.3076923076923077,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:24:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.3076923076923077,0.3333333333333333,0.3333333333333333,0.3303571428571428,0.3141025641025641,0.3076923076923077,0.3076923076923077,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:34:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,25,0.3076923076923077,0.3333333333333333,0.3333333333333333,0.3172619047619047,0.3397435897435897,0.3076923076923077,0.306959706959707,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:10:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3846153846153846,0.4214285714285714,0.4791666666666666,0.3361111111111111,0.4439560439560439,0.3846153846153846,0.3068376068376068,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:07:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.3846153846153846,0.3214285714285714,0.4791666666666666,0.35,0.2967032967032967,0.3846153846153846,0.2974358974358974,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:34:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.3846153846153846,0.3214285714285714,0.4791666666666666,0.35,0.2967032967032967,0.3846153846153846,0.2974358974358974,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:31:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.3846153846153846,0.3214285714285714,0.4791666666666666,0.35,0.2967032967032967,0.3846153846153846,0.2974358974358974,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:58:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.3846153846153846,0.25,0.4375,0.3166666666666666,0.2307692307692307,0.3846153846153846,0.2871794871794871,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:33:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,20,0.3076923076923077,0.3333333333333333,0.3958333333333333,0.3083333333333333,0.3205128205128205,0.3076923076923077,0.2717948717948718,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:21:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.3076923076923077,0.2458333333333333,0.3333333333333333,0.2777777777777777,0.2384615384615384,0.3076923076923077,0.2649572649572649,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:14:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3076923076923077,0.25,0.3333333333333333,0.2833333333333333,0.2307692307692307,0.3076923076923077,0.2615384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:26:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3076923076923077,0.3958333333333333,0.3958333333333333,0.2833333333333333,0.4230769230769231,0.3076923076923077,0.2615384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:07:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.3846153846153846,0.3333333333333333,0.375,0.2916666666666666,0.2564102564102564,0.3846153846153846,0.2564102564102564,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:49:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,15,0.3846153846153846,0.2071428571428571,0.4375,0.2792207792207792,0.1934065934065934,0.3846153846153846,0.2557442557442557,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:29:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,30,0.3846153846153846,0.3181818181818182,0.5,0.3571428571428571,0.2167832167832168,0.3846153846153846,0.2527472527472527,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:24:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3076923076923077,0.2857142857142857,0.3958333333333333,0.3,0.2637362637362637,0.3076923076923077,0.2512820512820513,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:50:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.3076923076923077,0.3055555555555556,0.3958333333333333,0.2742424242424243,0.3034188034188034,0.3076923076923077,0.2508158508158508,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:16:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3076923076923077,0.3055555555555556,0.3958333333333333,0.2742424242424242,0.3034188034188034,0.3076923076923077,0.2508158508158508,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:05:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.3076923076923077,0.2797619047619047,0.3958333333333333,0.2777777777777777,0.2747252747252747,0.3076923076923077,0.2478632478632478,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:26:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.3846153846153846,0.19375,0.4375,0.2678571428571428,0.1769230769230769,0.3846153846153846,0.2417582417582417,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:05:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.3076923076923077,0.2583333333333333,0.3958333333333333,0.2805555555555555,0.2282051282051282,0.3076923076923077,0.2376068376068376,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:45:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,5,0.3076923076923077,0.238095238095238,0.3958333333333333,0.2658730158730158,0.2234432234432234,0.3076923076923077,0.2332112332112332,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_5_2024-04-04_06:37:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-04_06:37:20.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,15,0.3076923076923077,0.2333333333333333,0.3958333333333333,0.2817460317460317,0.2,0.3076923076923077,0.2332112332112332,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-02_20:06:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_20:06:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.3076923076923077,0.238095238095238,0.3958333333333333,0.2658730158730158,0.2234432234432234,0.3076923076923077,0.2332112332112332,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:26:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,20,0.3076923076923077,0.238095238095238,0.3958333333333333,0.2658730158730158,0.2234432234432234,0.3076923076923077,0.2332112332112332,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:10:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.3076923076923077,0.238095238095238,0.3958333333333333,0.2658730158730158,0.2234432234432234,0.3076923076923077,0.2332112332112332,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:51:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.3076923076923077,0.1805555555555555,0.2916666666666666,0.2083333333333333,0.2051282051282051,0.3076923076923077,0.2307692307692307,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_35_2024-04-03_19:46:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_19:46:21.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.3076923076923077,0.2291666666666666,0.3958333333333333,0.2678571428571428,0.2115384615384615,0.3076923076923077,0.2307692307692307,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:45:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.3076923076923077,0.2291666666666666,0.3958333333333333,0.2708333333333333,0.2051282051282051,0.3076923076923077,0.2307692307692307,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:32:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,25,0.2307692307692307,0.2916666666666667,0.2708333333333333,0.275,0.2435897435897435,0.2307692307692307,0.2307692307692307,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:21:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.3846153846153846,0.2416666666666666,0.5,0.3153846153846154,0.1717948717948718,0.3846153846153846,0.229585798816568,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:15:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,10,0.3846153846153846,0.2416666666666666,0.5,0.3153846153846154,0.1717948717948718,0.3846153846153846,0.229585798816568,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:15:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.3846153846153846,0.2416666666666666,0.5,0.3153846153846154,0.1717948717948718,0.3846153846153846,0.229585798816568,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:33:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.3846153846153846,0.2416666666666666,0.5,0.3153846153846154,0.1717948717948718,0.3846153846153846,0.229585798816568,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:21:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3076923076923077,0.1964285714285714,0.375,0.2361111111111111,0.1978021978021978,0.3076923076923077,0.2222222222222222,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:27:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,35,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:25:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,15,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:24:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:19:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,35,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:13:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:52:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:28:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:27:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:29:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:21:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:48:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:08:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:02:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.3846153846153846,0.2083333333333333,0.5,0.2916666666666666,0.1538461538461538,0.3846153846153846,0.2179487179487179,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:02:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3846153846153846,0.1904761904761904,0.5,0.275,0.1501831501831501,0.3846153846153846,0.2153846153846153,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:34:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.3846153846153846,0.1904761904761904,0.5,0.275,0.1501831501831501,0.3846153846153846,0.2153846153846153,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:19:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:30:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:28:57.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:28:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,15,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:12:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,10,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:10:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:35:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:32:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:13:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:05:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:02:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.3846153846153846,0.19375,0.5,0.2792207792207792,0.148076923076923,0.3846153846153846,0.2137862137862137,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:00:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3076923076923077,0.2166666666666666,0.4166666666666666,0.25,0.1846153846153846,0.3076923076923077,0.2051282051282051,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:27:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,10,0.3076923076923077,0.2166666666666666,0.4166666666666666,0.25,0.1846153846153846,0.3076923076923077,0.2051282051282051,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:19:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.3076923076923077,0.2166666666666666,0.4166666666666666,0.25,0.1846153846153846,0.3076923076923077,0.2051282051282051,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:27:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,20,0.3076923076923077,0.2,0.4166666666666666,0.2678571428571428,0.1538461538461538,0.3076923076923077,0.2032967032967033,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:22:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,10,0.3076923076923077,0.3125,0.375,0.2666666666666666,0.2115384615384615,0.3076923076923077,0.1948717948717948,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:22:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3076923076923077,0.1964285714285714,0.4166666666666666,0.2666666666666666,0.1428571428571428,0.3076923076923077,0.1948717948717948,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:51:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.3076923076923077,0.3125,0.375,0.2666666666666666,0.2115384615384615,0.3076923076923077,0.1948717948717948,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:01:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.3076923076923077,0.1805555555555555,0.4166666666666666,0.2337662337662337,0.1495726495726495,0.3076923076923077,0.1878121878121878,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:16:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.3076923076923077,0.1805555555555555,0.4166666666666666,0.2337662337662337,0.1495726495726495,0.3076923076923077,0.1878121878121878,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:20:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3076923076923077,0.1805555555555555,0.4166666666666666,0.2337662337662337,0.1495726495726495,0.3076923076923077,0.1878121878121878,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:29:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.3076923076923077,0.1875,0.4166666666666666,0.2575757575757575,0.1346153846153846,0.3076923076923077,0.1864801864801864,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:25:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,30,0.3076923076923077,0.1666666666666666,0.4166666666666666,0.2361111111111111,0.1282051282051282,0.3076923076923077,0.1794871794871794,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:11:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.3076923076923077,0.1625,0.4166666666666666,0.225,0.1307692307692307,0.3076923076923077,0.1769230769230769,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:17:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.3076923076923077,0.1625,0.4166666666666666,0.225,0.1307692307692307,0.3076923076923077,0.1769230769230769,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:15:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.3076923076923077,0.1625,0.4166666666666666,0.225,0.1307692307692307,0.3076923076923077,0.1769230769230769,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:19:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.3076923076923077,0.1931818181818181,0.375,0.2321428571428571,0.1398601398601398,0.3076923076923077,0.1758241758241758,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:47:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.3076923076923077,0.1625,0.4166666666666666,0.2337662337662337,0.1192307692307692,0.3076923076923077,0.1718281718281718,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:22:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.2222222222222222,0.1208791208791208,0.3076923076923077,0.1709401709401709,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:30:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,5,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.2222222222222222,0.1208791208791208,0.3076923076923077,0.1709401709401709,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:24:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.2222222222222222,0.1208791208791208,0.3076923076923077,0.1709401709401709,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:15:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.2222222222222222,0.1208791208791208,0.3076923076923077,0.1709401709401709,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:35:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,10,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_10_2024-04-02_19:40:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_19:40:03.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,5,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:22:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:19:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:17:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:16:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:55:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:27:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:56:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3076923076923077,0.1547619047619047,0.4166666666666666,0.225,0.1172161172161172,0.3076923076923077,0.1692307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:05:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,5,0.3076923076923077,0.1583333333333333,0.375,0.2153846153846154,0.1205128205128205,0.3076923076923077,0.1680473372781065,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:16:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.2307692307692307,0.2916666666666667,0.3333333333333333,0.1964285714285714,0.2564102564102564,0.2307692307692307,0.1593406593406593,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:49:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,30,0.1538461538461538,0.1875,0.1875,0.1666666666666666,0.1923076923076923,0.1538461538461538,0.1538461538461538,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:13:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.2307692307692307,0.15,0.3333333333333333,0.2053571428571428,0.1076923076923077,0.2307692307692307,0.1456043956043956,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:06:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.2307692307692307,0.1547619047619047,0.3333333333333333,0.1944444444444444,0.1208791208791208,0.2307692307692307,0.1452991452991452,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:21:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3076923076923077,0.0769230769230769,0.25,0.1176470588235294,0.0946745562130177,0.3076923076923077,0.1447963800904977,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:56:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.2307692307692307,0.175,0.3333333333333333,0.1833333333333333,0.1461538461538461,0.2307692307692307,0.1435897435897435,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:49:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.2307692307692307,0.1357142857142857,0.3333333333333333,0.1928571428571428,0.0945054945054945,0.2307692307692307,0.134065934065934,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:50:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.2307692307692307,0.1388888888888889,0.3333333333333333,0.1742424242424242,0.1111111111111111,0.2307692307692307,0.1328671328671328,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:50:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,10,0.2307692307692307,0.113095238095238,0.2916666666666666,0.1625,0.0915750915750915,0.2307692307692307,0.1307692307692307,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_10_2024-04-04_06:39:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-04_06:39:01.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.2307692307692307,0.113095238095238,0.2916666666666666,0.1625,0.0915750915750915,0.2307692307692307,0.1307692307692307,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:13:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,20,0.2307692307692307,0.1333333333333333,0.3333333333333333,0.1666666666666666,0.1076923076923076,0.2307692307692307,0.1282051282051282,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:24:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,15,0.2307692307692307,0.1333333333333333,0.3333333333333333,0.1666666666666666,0.1076923076923076,0.2307692307692307,0.1282051282051282,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:22:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,5,0.2307692307692307,0.1333333333333333,0.3333333333333333,0.1666666666666666,0.1076923076923076,0.2307692307692307,0.1282051282051282,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:20:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,25,0.2307692307692307,0.1333333333333333,0.3333333333333333,0.1666666666666666,0.1076923076923076,0.2307692307692307,0.1282051282051282,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:14:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.2307692307692307,0.1125,0.2916666666666666,0.1623376623376623,0.0884615384615384,0.2307692307692307,0.1278721278721278,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:19:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.2307692307692307,0.125,0.3333333333333333,0.1714285714285714,0.0961538461538461,0.2307692307692307,0.1274725274725274,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:54:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.2307692307692307,0.1214285714285714,0.3333333333333333,0.1736111111111111,0.0901098901098901,0.2307692307692307,0.126068376068376,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_25_2024-04-03_19:02:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_19:02:48.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.2307692307692307,0.1214285714285714,0.3333333333333333,0.1736111111111111,0.0901098901098901,0.2307692307692307,0.126068376068376,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:58:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.2307692307692307,0.119047619047619,0.3333333333333333,0.175,0.0842490842490842,0.2307692307692307,0.123076923076923,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:25:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,10,0.2307692307692307,0.1180555555555555,0.3333333333333333,0.1623376623376623,0.0918803418803418,0.2307692307692307,0.1218781218781218,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:12:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.2307692307692307,0.1180555555555555,0.3333333333333333,0.1623376623376623,0.0918803418803418,0.2307692307692307,0.1218781218781218,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:15:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.2307692307692307,0.1180555555555555,0.3333333333333333,0.1623376623376623,0.0918803418803418,0.2307692307692307,0.1218781218781218,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:17:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.2307692307692307,0.113095238095238,0.3333333333333333,0.1666666666666666,0.0824175824175824,0.2307692307692307,0.1196581196581196,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:30:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.2307692307692307,0.113095238095238,0.3333333333333333,0.1666666666666666,0.0824175824175824,0.2307692307692307,0.1196581196581196,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:16:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.2307692307692307,0.1125,0.3333333333333333,0.1625,0.0846153846153846,0.2307692307692307,0.1192307692307692,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:31:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.2307692307692307,0.0681818181818181,0.25,0.1071428571428571,0.0629370629370629,0.2307692307692307,0.0989010989010989,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:28:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.1538461538461538,0.0857142857142857,0.2083333333333333,0.1214285714285714,0.0637362637362637,0.1538461538461538,0.0901098901098901,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:29:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,5,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:29:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,5,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:28:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:27:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,25,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:24:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:17:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,15,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:17:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,10,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:17:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:15:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,15,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:15:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,20,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:12:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:53:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:48:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:57:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:47:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:04:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:03:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.2307692307692307,0.0576923076923076,0.25,0.09375,0.0532544378698224,0.2307692307692307,0.0865384615384615,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:00:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.1538461538461538,0.0416666666666666,0.25,0.0714285714285714,0.0256410256410256,0.1538461538461538,0.0439560439560439,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:53:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.1538461538461538,0.0416666666666666,0.25,0.0714285714285714,0.0256410256410256,0.1538461538461538,0.0439560439560439,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:43:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.1538461538461538,0.0416666666666666,0.25,0.0714285714285714,0.0256410256410256,0.1538461538461538,0.0439560439560439,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:03:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_5_2024-04-02_19:38:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_19:38:47.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:29:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:29:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:29:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,15,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:28:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:28:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:28:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:27:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:27:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:26:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,15,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:25:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:25:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:25:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:24:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,15,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:20:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:20:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:19:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,15,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:19:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:18:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:18:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:17:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:16:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,15,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:16:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:16:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:15:09.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:14:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:14:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,20,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:14:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,15,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:14:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,10,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:14:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:13:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:12:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:11:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,15,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:10:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,5,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_21:10:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
4,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-09_07:43:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-09_05:59:38.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:31:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:31:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:29:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:27:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_23:25:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:20:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:19:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:18:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:28:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:25:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:24:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:24:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:17:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_21:13:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:58:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:58:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:52:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_08:48:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:08:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:06:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:06:27.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:04:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.1538461538461538,0.0384615384615384,0.25,0.0666666666666666,0.0236686390532544,0.1538461538461538,0.041025641025641,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:02:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
4,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.0769230769230769,0.0277777777777777,0.125,0.0454545454545454,0.017094017094017,0.0769230769230769,0.0279720279720279,/Human_Activity_Video_Recognition/data/output/models/DVORAK_CUSTOM/human_activity_recognition_model_4_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_07:31:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
