number_of_classes,image_height,image_width,sequence_length,random_state,model_type,output_layer_activation_function,loss_function,adam_optimizer_learning_rate,training_shuffle,max_training_epochs,batch_size,early_stopping,early_stopping_monitor,early_stopping_mode,early_stopping_patience,accuracy,macro_precision,macro_recall,macro_f1,weighted_precision,weighted_recall,weighted_f1,model_output_path,architecture_and_evaluation_output_path
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.4915254237288136,0.5084788594556596,0.4889636461483695,0.4894867582741899,0.5152170073246284,0.4915254237288136,0.4938667312961604,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-02_18:12:27.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_18:12:27.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.4343220338983051,0.431440745245093,0.4323930994269706,0.4286971501333837,0.439108353367749,0.4343220338983051,0.4333256240921154,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-03_20:25:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_20:25:47.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.4088983050847458,0.4627186903306127,0.4187140512014062,0.4158032943334689,0.4653429114470512,0.4088983050847458,0.4160912282734725,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_20_2024-04-02_20:15:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_20:15:48.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.3961864406779661,0.4518941063338735,0.3983949731863011,0.3989005996899963,0.4542888916974115,0.3961864406779661,0.3987559781723852,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_30_2024-04-03_19:16:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_19:16:05.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,10,0.3940677966101695,0.4403360331773771,0.4027480168456062,0.3970850499045291,0.4499357818010527,0.3940677966101695,0.3974573323557605,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_10_2024-04-02_19:46:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_19:46:35.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.3622881355932203,0.41188011201811,0.3644934081148079,0.3633811880963795,0.4142079276522435,0.3622881355932203,0.3654663398352339,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_35_2024-04-03_19:24:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_19:24:44.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,5,0.3644067796610169,0.3747689671968848,0.3666825197562987,0.3608836354582733,0.3743982237414925,0.3644067796610169,0.359730986435864,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_5_2024-04-02_19:19:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_19:19:18.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,15,0.3538135593220339,0.3813483299752613,0.3527344161992825,0.3517407297317921,0.3821501040149361,0.3538135593220339,0.3528172333213327,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-02_19:52:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-02_19:52:47.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3516949152542373,0.3702399331751537,0.3610065675372232,0.3493975370930769,0.3716995060341897,0.3516949152542373,0.3452465210434374,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_25_2024-04-03_18:46:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-03_18:46:38.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,10,0.3093220338983051,0.3897090563691596,0.3109249680620312,0.3179793442643301,0.385495571185126,0.3093220338983051,0.3142562318113827,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_10_2024-04-04_06:45:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-04_06:45:42.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,15,0.2923728813559322,0.34068918723136304,0.30484423816799733,0.2984624209311311,0.3440130167503932,0.2923728813559322,0.2960137650574582,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-04_06:53:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-04_06:53:19.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,5,0.3114406779661017,0.3708059667599365,0.3157934267657695,0.3016406414756681,0.3725134719851987,0.3114406779661017,0.2960118839879984,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_5_2024-04-04_06:27:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-04_06:27:24.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.4088176352705411,0.4236650345997449,0.4045307349615155,0.4058914038357253,0.4271547134494447,0.4088176352705411,0.408793664599309,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-05_13:50:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.3987975951903807,0.4052249920376055,0.4150754161553779,0.4028525754766505,0.4003240720482827,0.3987975951903807,0.3923802560433115,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-05_11:08:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,False,val_loss,min,5,0.3847695390781563,0.39997499656425,0.3889860875233474,0.3873874464184461,0.4042404740247439,0.3847695390781563,0.3875241495596669,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8_2024-04-05_09:33:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.3867735470941884,0.3940992332710921,0.3888535038668083,0.38425402625371,0.3929456617531182,0.3867735470941884,0.3811396080805783,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-05_13:32:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,False,val_loss,min,5,0.376753507014028,0.3973338936750958,0.3826822606659708,0.380552572382398,0.4011506944682563,0.376753507014028,0.3785253774326323,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16_2024-04-05_10:10:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,False,val_loss,min,5,0.3847695390781563,0.3872398588033811,0.3888120471233945,0.3794065951827721,0.3910706550603238,0.3847695390781563,0.3782024032313179,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8_2024-04-05_12:11:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,False,val_loss,min,5,0.3727454909819639,0.3724832975525195,0.3712732556937578,0.3663183160229192,0.3797260170429392,0.3727454909819639,0.3707998938117425,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4_2024-04-05_11:13:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,30,0.3687374749498998,0.3802786887846288,0.3608859258846519,0.361106164903168,0.3838132021988884,0.3687374749498998,0.3658163041874122,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:28:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3727454909819639,0.3849185758908172,0.3788583191767263,0.3716957999339981,0.3833659803117367,0.3727454909819639,0.3657720568087244,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-05_10:50:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.3647294589178356,0.3730074528502051,0.3676816987229728,0.365081182758494,0.3776251007160853,0.3647294589178356,0.3654542887677832,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-05_11:02:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,10,0.3727454909819639,0.3885467504601591,0.363860723005604,0.3602442198068811,0.3983799126031613,0.3727454909819639,0.3647449945841743,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:46:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,False,val_loss,min,5,0.3707414829659318,0.3698912789605724,0.370074274222232,0.3601399005293773,0.3795632276822374,0.3707414829659318,0.3631009748054446,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4_2024-04-05_08:29:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,15,0.3707414829659318,0.3845972059986756,0.3816304989922016,0.3715002485702353,0.3835261059056444,0.3707414829659318,0.3624089412894247,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:53:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.3707414829659318,0.3639026183682681,0.3585645354139479,0.3549416394224667,0.369062124214976,0.3707414829659318,0.3613922863263302,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:49:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.3627254509018036,0.3722126084534828,0.3689672529650992,0.3634165093472639,0.3670230511992048,0.3627254509018036,0.3569218692791465,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-05_13:16:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.3547094188376753,0.3629997679557989,0.361655225507335,0.3570634729392689,0.3685176035700406,0.3547094188376753,0.35548646333594,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-05_13:44:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,False,val_loss,min,5,0.3567134268537074,0.3619345177619094,0.3489237407222788,0.3458946287614056,0.3742523180635812,0.3567134268537074,0.3548522808629605,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16_2024-04-05_12:50:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.3466933867735471,0.374333797988157,0.3368289199844591,0.3430775744864233,0.3826539523867625,0.3466933867735471,0.3493197598010332,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:57:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.3587174348697395,0.356653116325004,0.3460249842990863,0.3425773089930102,0.3598984388272994,0.3587174348697395,0.3474730410663951,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:07:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,5,0.3527054108216433,0.3437184346891802,0.3423760778334793,0.3366264095826056,0.3507833523485438,0.3527054108216433,0.3442824806849495,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:30:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,10,0.3466933867735471,0.3548228285035961,0.334370441008171,0.3349487266925913,0.362305319465827,0.3466933867735471,0.3432325230333312,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:04:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.344689378757515,0.349495510623371,0.3386461187559201,0.3366859286660378,0.3589312768243514,0.344689378757515,0.3429770104845439,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:05:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.3466933867735471,0.350776681470937,0.3353051169553823,0.335136205457701,0.3558706012070147,0.3466933867735471,0.3426133207372049,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:54:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,15,0.344689378757515,0.3577265169648482,0.3388038721006531,0.3402400883785978,0.3573304234232869,0.344689378757515,0.3425258575518338,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:38:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.344689378757515,0.3531407104432819,0.3381870457039558,0.3362690652328373,0.3654365652447404,0.344689378757515,0.3417222604113203,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:49:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,15,0.3507014028056112,0.3595742957401727,0.3252503408069794,0.3266043846130883,0.3686200815437778,0.3507014028056112,0.3394738007304433,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:47:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,15,0.342685370741483,0.3395735001259743,0.3384095414461571,0.330757132113518,0.3510951309552858,0.342685370741483,0.3381813910249083,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:10:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.3386773547094188,0.3387311166822609,0.3382235214686707,0.3329295176935727,0.3428505605285672,0.3386773547094188,0.3357213816565969,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-05_10:34:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.3406813627254509,0.3578560443805231,0.3361757820136903,0.3331059282419608,0.3609923145052948,0.3406813627254509,0.3347369397812811,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:11:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.3366733466933868,0.3664212585632694,0.3321337359000931,0.3320261660060096,0.373520934663214,0.3366733466933868,0.334668278168383,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:58:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,25,0.3486973947895792,0.3893328927484632,0.3360225002839251,0.3294964466406297,0.3865523603371379,0.3486973947895792,0.3325013754991133,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:08:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.3366733466933868,0.3475847095632564,0.3329966185905747,0.3286051227349677,0.3539507363147589,0.3366733466933868,0.3314074117016488,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:11:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,10,0.3366733466933868,0.3327245755696582,0.3183028149731032,0.3155888626852257,0.3434029676673408,0.3366733466933868,0.3290276023410603,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:37:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.3346693386773547,0.3297533269731545,0.3220040415685138,0.3183287518794115,0.3422046408381146,0.3346693386773547,0.3285730060049671,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:12:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,25,0.3266533066132264,0.3545337398021979,0.3179277295802544,0.3210448165155909,0.3664518963099265,0.3266533066132264,0.3282528411200029,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:39:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,15,0.3226452905811623,0.3351879537529524,0.3118994873383682,0.3172676367843843,0.3466528201134377,0.3226452905811623,0.3278975585027517,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:04:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,15,0.3386773547094188,0.3271444964736609,0.3199554438813713,0.3129155751624706,0.3388516916682882,0.3386773547094188,0.3269640837292164,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:43:25.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,20,0.3346693386773547,0.3354728744486004,0.3222065711275949,0.3182035908268484,0.3401300092862437,0.3346693386773547,0.3267239400910563,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:36:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.3326653306613226,0.356288581307124,0.3214145630648283,0.3217139407169646,0.3622428985195758,0.3326653306613226,0.3258980959299161,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:54:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3226452905811623,0.3571910202897488,0.3049510194253886,0.3083435143009556,0.3722245372155468,0.3226452905811623,0.3248187875710067,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:30:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3166332665330661,0.3395628075277649,0.3122542048122423,0.3176712687822028,0.3449827845917483,0.3166332665330661,0.3229050536857605,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:48:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,5,0.3306613226452906,0.3310529702947683,0.3223168305423656,0.3151952960657054,0.3368623722833531,0.3306613226452906,0.3223117147574216,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:04:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.342685370741483,0.3714154226840084,0.3298349774959297,0.3213498883967478,0.3673056559136667,0.342685370741483,0.3212564010511562,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:26:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.3226452905811623,0.342960300574833,0.3148612297276317,0.3145592380825776,0.3460181400109621,0.3226452905811623,0.3201677239660766,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:47:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,10,0.3246492985971944,0.3420227660162696,0.3227824874929249,0.3167858095057233,0.3450516426730527,0.3246492985971944,0.3200662904654623,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:03:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,5,0.3266533066132264,0.3263794770526888,0.3197806609668666,0.3125466159642658,0.3367846584823596,0.3266533066132264,0.3193712885480163,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:46:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,30,0.312625250501002,0.3348266718719863,0.2977314042932734,0.3043829816423322,0.3419267527962962,0.312625250501002,0.3164399735426788,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:10:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.3326653306613226,0.3118515393021493,0.3158012692109643,0.298759051943644,0.3330722787590913,0.3326653306613226,0.3161227034522424,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:13:02.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,15,0.3206412825651302,0.3399648966160893,0.3107274316168995,0.3094941898254449,0.3454318142742063,0.3206412825651302,0.3126932171867038,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:05:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.312625250501002,0.3291308406087818,0.3014594142466212,0.3001074271173435,0.3442496994247554,0.312625250501002,0.3093781450076532,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:47:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.314629258517034,0.3240264270490936,0.297553794204949,0.2977778321802074,0.3269267824828385,0.314629258517034,0.3077441931142261,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:28:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.3166332665330661,0.334313062874618,0.3000553128430006,0.3033104691229941,0.3369742519299463,0.3166332665330661,0.3075195907702969,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:59:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,30,0.3186372745490982,0.3343151318787761,0.3179700949232275,0.3051930694333479,0.3360051950411732,0.3186372745490982,0.3064903974300064,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:02:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,5,0.3166332665330661,0.3073594759376786,0.3101366703768127,0.2989299540473236,0.3211404766910871,0.3166332665330661,0.3064363341217243,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:37:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,15,0.3026052104208417,0.3414992255420025,0.3028950909320431,0.3027725699059133,0.3521253416892231,0.3026052104208417,0.3062721067215807,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:34:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3206412825651302,0.3198873858435977,0.3014254823376172,0.2931756265528346,0.3314867266079109,0.3206412825651302,0.3024908348604574,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:53:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,35,0.3166332665330661,0.3386402592198571,0.3147480966884414,0.3060869638739949,0.3310492619800344,0.3166332665330661,0.3022872135840613,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:13:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,15,0.312625250501002,0.3193282985760443,0.3081881460571512,0.3005381661019222,0.3206342614160166,0.312625250501002,0.3019133872163556,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:47:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.31462925851703405,0.31774127476334607,0.2955459318821648,0.29383284557347783,0.32623601713268313,0.31462925851703405,0.30159546321651826,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:55:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,35,0.3026052104208417,0.3337385101396131,0.2932433236492497,0.2925376319342155,0.339405632415206,0.3026052104208417,0.3014221564639143,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:05:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.314629258517034,0.3141073860646229,0.2877223215861371,0.2853220836024553,0.3212486558164757,0.314629258517034,0.3000897793297077,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:00:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,15,0.3046092184368738,0.301371204072111,0.2892747024012168,0.2876308743884194,0.3084743565655552,0.3046092184368738,0.2980031565816231,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:56:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.3086172344689378,0.318288933737021,0.2831930437758947,0.2792614875057313,0.3341757548447353,0.3086172344689378,0.2970292905155359,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:27:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.314629258517034,0.3196997871746733,0.3071136830871846,0.2987951108942367,0.3190732474553538,0.314629258517034,0.296425515653514,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:42:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,20,0.3106212424849699,0.3229919043763211,0.3111790462185632,0.2966205170813612,0.3205975684332374,0.3106212424849699,0.2959015201203973,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:12:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.3086172344689378,0.3003808625881963,0.2889402692995394,0.2827414344624532,0.3116185864064718,0.3086172344689378,0.2957768570460122,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:49:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,25,0.3066132264529058,0.3210469544468184,0.2983719576694141,0.2862181534104843,0.3391954550518506,0.3066132264529058,0.2951186377505171,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:59:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,20,0.2985971943887776,0.308796415209388,0.2795303713690754,0.2786055120804586,0.3188808638177257,0.2985971943887776,0.2936377543222791,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:06:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,10,0.312625250501002,0.2945545651911262,0.3089129737496658,0.289758655124485,0.3025067489031937,0.312625250501002,0.2929957072383417,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:52:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,16,True,val_loss,min,5,0.3046092184368738,0.3318781080580987,0.2821733650173836,0.2831521288397797,0.3403163738973186,0.3046092184368738,0.2913178067608629,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:02:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3086172344689378,0.2821709097825396,0.2898512687014071,0.2767996149390826,0.2969043962922382,0.3086172344689378,0.2904157790572387,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:40:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.3086172344689378,0.3481445674718944,0.2827030512761985,0.2770380204022715,0.3459297962237312,0.3086172344689378,0.2896610576235217,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:06:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,30,0.2965931863727455,0.33103417458446,0.2917780769167588,0.2826143347416871,0.3449450620843928,0.2965931863727455,0.2868924312099908,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:21:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,5,0.3046092184368738,0.287645654839919,0.2898409316453107,0.2778416841128507,0.2966455988491076,0.3046092184368738,0.2867809972553168,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:09:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,10,0.3026052104208417,0.3102132638273532,0.2872504511718114,0.2785630212858608,0.3197518562033653,0.3026052104208417,0.2866776103650178,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:42:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,10,0.3066132264529058,0.3286465611176662,0.3051649658078974,0.2811282669830397,0.3521282057019363,0.3066132264529058,0.2865295986051921,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:06:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.2905811623246493,0.294082671762467,0.2745539450678096,0.2749625936127916,0.3012931821647419,0.2905811623246493,0.2858844685593853,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:44:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.3026052104208417,0.2890677221717205,0.3060508749727881,0.2824469309034058,0.2961734219541762,0.3026052104208417,0.2851005579516562,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:41:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,5,0.2905811623246493,0.3072686799089005,0.2922125549170983,0.2864489894417707,0.307726788554989,0.2905811623246493,0.2836410698104486,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:23:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,10,0.3046092184368738,0.3016228628522456,0.2871228302160291,0.2739782280644216,0.3106520240728428,0.3046092184368738,0.2822014380232968,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:32:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.3106212424849699,0.2918841022431789,0.2877804867713142,0.2718108493627388,0.2913326065287276,0.3106212424849699,0.2804769516448296,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:06:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,35,0.2985971943887776,0.3238976381569283,0.2731181814604405,0.2674013129827768,0.341959948888087,0.2985971943887776,0.2799434791552775,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:46:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,5,0.312625250501002,0.3056883438747255,0.2792373749892546,0.2620620778253339,0.3188860880904114,0.312625250501002,0.278449453348234,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:42:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,10,0.2985971943887776,0.2809822758665466,0.2779400136274018,0.2640470177640701,0.2964219538426206,0.2985971943887776,0.278175767121189,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:44:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,10,0.282565130260521,0.2720804244774833,0.2603982511510202,0.2550865422293066,0.2843720759181091,0.282565130260521,0.2693517200074602,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:10:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.2945891783567134,0.2985975255129418,0.2748288938574474,0.2617420760047858,0.3097783262213641,0.2945891783567134,0.2689542253180955,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:39:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,20,0.2845691382765531,0.2947723037751001,0.2631277874335366,0.2526439578576643,0.3108634409675321,0.2845691382765531,0.2672344971228305,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:56:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,5,0.280561122244489,0.2820610816122887,0.2536389134846676,0.2470222233345853,0.292563351717118,0.280561122244489,0.2669821933230811,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:41:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,5,0.2865731462925852,0.2795607815593444,0.2806260222160266,0.264358332574154,0.2857699486859881,0.2865731462925852,0.2667377630104491,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:04:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,8,True,val_loss,min,30,0.2785571142284569,0.335188930059804,0.2764468586517675,0.2656594275205283,0.363237452231521,0.2785571142284569,0.2662153024262675,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_12:43:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,20,0.2765531062124248,0.292460428496728,0.2816657493743791,0.264004303950688,0.2963088698381531,0.2765531062124248,0.2646561116752728,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:50:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,15,0.2785571142284569,0.282682498691819,0.2757692179129044,0.2573204880399369,0.2929736946522022,0.2785571142284569,0.2599383164530348,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:25:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,25,0.280561122244489,0.3082439438136769,0.2665732291166881,0.2534099213345497,0.3109203032486814,0.280561122244489,0.2580869263548797,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:54:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,35,0.2665330661322645,0.2706786786556523,0.2467109900813845,0.2433245361994822,0.2807255905261126,0.2665330661322645,0.2563344509629022,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:31:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.2705410821643286,0.2553802983423824,0.2428336914102398,0.238890285385177,0.2652257812686507,0.2705410821643286,0.2546512385422343,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:45:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,5,0.280561122244489,0.2824154675311034,0.2602796373065877,0.242082745312217,0.3014357781986836,0.280561122244489,0.254547432332093,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:21:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,15,0.2705410821643286,0.27738578731211,0.2555709141150606,0.2415080326873141,0.2919583564172037,0.2705410821643286,0.2512881632601816,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:23:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,10,0.2785571142284569,0.2822224771262883,0.2496719783524511,0.2393167885392713,0.2884954317934979,0.2785571142284569,0.2511132428246294,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:24:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,5,0.2725450901803607,0.3103989782503903,0.2425746903045568,0.2397381413607415,0.3125504956080099,0.2725450901803607,0.2503379918125318,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:55:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,10,0.2645290581162324,0.2433006571683943,0.2510833658392813,0.2379907708118047,0.2553248268726004,0.2645290581162324,0.2481645018557116,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:56:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,35,0.2705410821643286,0.2617227897466539,0.251985803091833,0.2311819725820263,0.2732392734688204,0.2705410821643286,0.2457462081302745,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:06:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,25,0.280561122244489,0.3039434671590374,0.2750329798471372,0.2475335846812073,0.2957973957011146,0.280561122244489,0.245359036416838,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:16:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,15,0.2585170340681362,0.2597043315352639,0.2535457210853702,0.2344464126222913,0.272029456978317,0.2585170340681362,0.2417401495497361,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:09:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,4,True,val_loss,min,35,0.2685370741482966,0.2625269702964328,0.2548442575010513,0.2359192378140548,0.2574890387322114,0.2685370741482966,0.2374524068355016,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:27:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,4,True,val_loss,min,30,0.2565130260521042,0.236030484499519,0.240642870798018,0.2259631088879665,0.2431693023215098,0.2565130260521042,0.2366506506825414,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_4__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_11:59:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,5,0.2765531062124248,0.2472205040811275,0.2498209193104199,0.2169779787493874,0.2570743601904512,0.2765531062124248,0.2276839683516605,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:51:52.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,25,0.2625250501002004,0.2437777430870954,0.2449220550891247,0.2140368533512438,0.2612212972025666,0.2625250501002004,0.2246707902615089,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:26:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,10,0.2464929859719438,0.202102138439386,0.2244996043042309,0.1942510696328345,0.2110039477942251,0.2464929859719438,0.2067377453312275,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:22:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,15,0.2344689378757515,0.2120586078995194,0.2162794915056803,0.1856226440119827,0.2081099068262037,0.2344689378757515,0.1904929736304991,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:54:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,16,True,val_loss,min,20,0.218436873747495,0.1911207666659193,0.1970890269023069,0.1722424649020313,0.2027978281021623,0.218436873747495,0.1846946958436447,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_16__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_10:25:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,8,True,val_loss,min,10,0.2404809619238476,0.1755558074918152,0.2173362007693199,0.1713784551582878,0.1867991562501391,0.2404809619238476,0.1819422236742125,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_8__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_09:53:02.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,32,32,5,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,5,0.2364729458917835,0.1925599427587414,0.2065911363892129,0.1703730651088093,0.205354856972738,0.2364729458917835,0.1819176344971099,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_13:52:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_08:29:48.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.5084745762711864,0.5301321896997939,0.5079906785234252,0.5067059979492764,0.5437582553963787,0.5084745762711864,0.5119567027093745,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-08_06:05:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.4915254237288136,0.5019913823325148,0.4917173504365763,0.4892402972509633,0.5122377869948632,0.4915254237288136,0.4941514903358131,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-08_03:18:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.4851694915254237,0.4895006142992192,0.4896838554881442,0.4847209289248263,0.4906117431824598,0.4851694915254237,0.4831262602097072,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-08_02:15:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.4703389830508475,0.4927669827077722,0.4703894661710688,0.4730493248267436,0.5010583486656747,0.4703389830508475,0.4776517596293739,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-08_01:21:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.4724576271186441,0.4764116855467109,0.4795853332162808,0.4690364335953223,0.4839921334660586,0.4724576271186441,0.4699221199109175,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-08_04:14:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.4661016949152542,0.4805633993112216,0.4713198859292917,0.4651384428597257,0.4840468521584337,0.4661016949152542,0.4636591005391795,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-07_23:36:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.461864406779661,0.4711428149977625,0.4640900267854224,0.4611332492996685,0.479065232683683,0.461864406779661,0.4636202734734772,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-08_07:22:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-08_07:22:15.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.4576271186440678,0.4712961575619997,0.4623132676940182,0.4597495708681651,0.4748336203140289,0.4576271186440678,0.4593348204607325,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-08_00:30:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.4613686534216336,0.4665190566414486,0.472329182492226,0.4621891304886961,0.4667577705771369,0.4613686534216336,0.4568042714785911,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_10:40:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.4555084745762712,0.461813200088795,0.4587916488137036,0.4564779098463551,0.4641176872953233,0.4555084745762712,0.4558866743128251,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-08_05:08:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.4470338983050847,0.5287645685007586,0.4512237355917621,0.4450220872809658,0.5367954834744094,0.4470338983050847,0.4419524142313542,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_04:47:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.4336099585062241,0.4295409289101834,0.4368635788833553,0.4259057150474223,0.4425825193498264,0.4336099585062241,0.4316670138213692,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-05_23:33:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.437759336099585,0.4155201171486483,0.4391803575891951,0.4215878100127331,0.4265908015275954,0.437759336099585,0.4266680382324082,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-05_23:46:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.4152542372881356,0.4535898752428444,0.4128749353298591,0.4154904239769125,0.4645052080782726,0.4152542372881356,0.4221861531542298,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_08:07:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-08_07:22:15.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.4110169491525424,0.4653349264224923,0.4206486373753201,0.4190691200832252,0.4743496086074796,0.4110169491525424,0.41946910044183,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_06:37:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.4147286821705426,0.4476878291889264,0.4269469746787017,0.426209398750118,0.4319324231252808,0.4147286821705426,0.4122988603156518,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-07_09:49:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.4105960264900662,0.4304492614989849,0.4230957870631783,0.417217917616717,0.424511851786316,0.4105960264900662,0.4071596214104148,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_10:11:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.3961864406779661,0.4361679990511261,0.4012304471197985,0.3998339976962658,0.4430997212911338,0.3961864406779661,0.4013999656456835,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_05:36:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.3992248062015504,0.4423660686917187,0.4191242124879054,0.4194187048879271,0.4231441666901461,0.3992248062015504,0.4000011600996911,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-07_08:46:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.3834745762711864,0.4542476553474495,0.3858446353644017,0.3955513783081091,0.4605466220699045,0.3834745762711864,0.3978771708951764,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_00:57:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.3914728682170542,0.4564593474158692,0.4120654834906248,0.4226568835550782,0.4273561030588331,0.3914728682170542,0.3977703216149666,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-07_11:21:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.4083885209713024,0.4245951263109505,0.4196880494706582,0.403691450203456,0.4232475176021272,0.4083885209713024,0.3965235186005972,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_11:23:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.3934108527131782,0.4356843396209353,0.4080158132382018,0.4120962365882604,0.4149201895631115,0.3934108527131782,0.3952667916700736,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-07_09:15:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3934108527131782,0.4328465268841852,0.4225631030943152,0.4194577588940434,0.4097866675255252,0.3934108527131782,0.3941521416973751,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-07_08:17:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.4045643153526971,0.3930184613261016,0.4147499703882141,0.3951250872419346,0.397412090633059,0.4045643153526971,0.3935744390915874,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-05_23:53:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.3940677966101695,0.4279720664705689,0.3933904237692804,0.3877045395898625,0.4354301818044621,0.3940677966101695,0.3900702041156585,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_03:59:27.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.3953488372093023,0.4187883539622438,0.4084297903000117,0.4025528121934166,0.4071394493633463,0.3953488372093023,0.3897199334249859,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-07_10:17:04.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.3961864406779661,0.4487834292583971,0.3996450146518599,0.3883655289086077,0.4528590803894865,0.3961864406779661,0.3892823450969428,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_00:23:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.401766004415011,0.3992288217789179,0.417562383268905,0.3969292670523515,0.3975718847898694,0.401766004415011,0.3873180500874186,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_08:59:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.3940677966101695,0.4227013408980913,0.4016592238645621,0.3926565851426784,0.4216032351018773,0.3940677966101695,0.3872617458632935,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_02:47:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.3961864406779661,0.4298078658293678,0.406948449305764,0.3918086129313778,0.4316332480203152,0.3961864406779661,0.3870175411772699,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_05:49:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3792372881355932,0.4654932456755938,0.3862412575230574,0.3859260440888085,0.4788844755186583,0.3792372881355932,0.3861435415596868,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_04:07:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.3728813559322034,0.4363980392434711,0.3748777736046536,0.3803970876054027,0.4410951651702537,0.3728813559322034,0.3827312326254071,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_02:07:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.3875278396436525,0.3896294499664682,0.3939008053350159,0.3805875171472526,0.4006782251782101,0.3875278396436525,0.3810175928805861,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_23:12:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3853006681514476,0.381310443920523,0.3836519805730332,0.377270235318507,0.3853711484398334,0.3853006681514476,0.3803504587467999,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_22:41:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.3808463251670378,0.4031300266077943,0.3818037476655898,0.3781862080038992,0.4047364679674228,0.3808463251670378,0.379975326042565,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_23:34:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.3837209302325581,0.420562099252449,0.4030044058383001,0.3964641088202371,0.4029742447473283,0.3837209302325581,0.378318300102583,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-07_07:32:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.376391982182628,0.3742283345432567,0.3755123468149784,0.368544531259665,0.3855451220645185,0.376391982182628,0.3743423164413151,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_21:28:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.3808463251670378,0.4046680282116856,0.3796000967843073,0.3724250208807826,0.402657467154351,0.3808463251670378,0.373883939654563,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-07_01:15:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.3719376391982182,0.3684421162104531,0.3702307947900053,0.3624954211308815,0.3842950714383242,0.3719376391982182,0.3717585642035957,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_23:56:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.3775933609958506,0.3999020091180981,0.3937803097617323,0.3764777465287653,0.4033492407168633,0.3775933609958506,0.3713774796422635,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-05_23:13:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.3701550387596899,0.4236921053521289,0.3757521863534281,0.3766797053334088,0.4173564619420264,0.3701550387596899,0.3702559807149841,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:06:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3775933609958506,0.3662981821997497,0.3770003750158407,0.3639069975712221,0.3778521251542442,0.3775933609958506,0.3699440404844606,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:50:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3796680497925311,0.3781200978076365,0.3955042142971693,0.3772189850461275,0.3763544989533165,0.3796680497925311,0.3692885220163007,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-05_22:47:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.3730684326710817,0.3830617716372516,0.3777286320764582,0.3681491856375893,0.3887053324013385,0.3730684326710817,0.3686053162225828,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_11:01:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3755186721991701,0.3655932700666472,0.3767493054280882,0.3579477707854376,0.3841029718474432,0.3755186721991701,0.3671914185153668,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:41:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.3686440677966102,0.4016932383621313,0.371972903557335,0.3703307067360432,0.4007580787355481,0.3686440677966102,0.3670556193030391,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_06:44:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3701550387596899,0.4263440039431347,0.3745755480398265,0.3774771418791123,0.4091719859550631,0.3701550387596899,0.3667162119880224,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:06:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.3730684326710817,0.3734186347026637,0.3890940902897424,0.3759498292071785,0.3672114171616882,0.3730684326710817,0.3656005243860459,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_12:52:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.3796680497925311,0.3770406873215893,0.3775156707275143,0.3565274777949418,0.3892852681616853,0.3796680497925311,0.3638208633914347,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:24:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.3692946058091286,0.3615316745360619,0.3753333792946318,0.3594628375061864,0.3712287010230072,0.3692946058091286,0.3623854504926765,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-05_23:00:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.3546511627906977,0.4081426423184607,0.3662072612729498,0.3767399240692779,0.3912563738727271,0.3546511627906977,0.3616996325113323,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:15:25.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.3622881355932203,0.3934151593350762,0.3633223927452997,0.3598603292795406,0.39733895773216,0.3622881355932203,0.3614194263713949,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_00:04:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.3719376391982182,0.3802620356888921,0.3844346830070514,0.3659184968976461,0.3814664100312392,0.3719376391982182,0.3603999371439919,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-07_01:37:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3580508474576271,0.3753587736236897,0.353840603109245,0.3547822032225878,0.3821027111597315,0.3580508474576271,0.3594544341643854,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_07:54:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-08_07:22:15.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.3580508474576271,0.409707354587163,0.3659213259626737,0.3599666257708137,0.4111127403199974,0.3580508474576271,0.3572320521077605,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_03:52:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.3559322033898305,0.3907896504790425,0.3610921088498812,0.3535137191575804,0.4000093778407911,0.3559322033898305,0.3564583613103753,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_05:57:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3559322033898305,0.3988009738894612,0.3653935777041986,0.3550958190329139,0.4021847799690883,0.3559322033898305,0.3550764135376064,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_07:01:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.3622881355932203,0.3781108179234862,0.3659676810318923,0.3520470712723192,0.3820468879972919,0.3622881355932203,0.3517423243325697,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_04:53:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.3509933774834437,0.3747490964073114,0.3489471760123934,0.3508913947884358,0.3704127675777126,0.3509933774834437,0.3513297463730365,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_11:20:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.3538135593220339,0.3801557524233692,0.3549685832825973,0.3487631583154257,0.3860956895610414,0.3538135593220339,0.3500582498680523,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_03:10:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.3601694915254237,0.3861903542947301,0.3574789599769872,0.3443874003462688,0.3955095527220615,0.3601694915254237,0.3498226568448525,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_00:10:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.3453389830508475,0.3949713487239811,0.3551634070752275,0.348185739270866,0.3982258831989163,0.3453389830508475,0.3483730684705242,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_05:43:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.3601694915254237,0.400843361727313,0.3606580369722483,0.3455623480757313,0.4108352450902924,0.3601694915254237,0.3481190914871606,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_01:02:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.3532008830022075,0.4096605315133674,0.359472011482881,0.3549179647180841,0.4009334373361691,0.3532008830022075,0.3469406637238807,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:26:09.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.3651452282157676,0.3591532635898066,0.3811239891042127,0.3512335866657585,0.3652446933779514,0.3651452282157676,0.3468925446324105,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-05_22:16:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.3487858719646799,0.3688199867283351,0.3566009614379179,0.3469782485920047,0.3727588031839182,0.3487858719646799,0.3466282583989954,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_12:33:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.3563474387527839,0.3683532308837819,0.3672722947130842,0.3524474698676495,0.361591489431233,0.3563474387527839,0.3463562522588622,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-07_00:44:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.3598233995584989,0.3524898278787864,0.3682301273605621,0.34937195818075,0.3525445596667467,0.3598233995584989,0.3452142439169137,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_11:48:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3507751937984496,0.3961862722530055,0.3547450455069077,0.3520048228212595,0.3872819209546906,0.3507751937984496,0.3451169890415475,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:37:55.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.3516949152542373,0.3733087297541091,0.3583063958261623,0.3447715401751025,0.3814993875563359,0.3516949152542373,0.3440961010428668,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_06:52:29.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.3568464730290456,0.3589846722397501,0.3518530375604792,0.3390903552376734,0.3592726127539749,0.3568464730290456,0.3426059163288493,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:45:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.3495762711864407,0.3808242342912329,0.3494319409938837,0.3392706610156204,0.3904888286494152,0.3495762711864407,0.3421562891207529,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_05:00:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3532008830022075,0.3626590473873022,0.354076820924647,0.3455975702489741,0.3578501664913769,0.3532008830022075,0.3416410289960119,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:20:25.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.3516949152542373,0.3617961111691762,0.3604277018948564,0.3422483126017277,0.3611102066983599,0.3516949152542373,0.3395976595488021,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_00:16:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3509933774834437,0.3440255274361588,0.3503776738559347,0.3393451708156846,0.3428866572290362,0.3509933774834437,0.3395057048307945,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_13:03:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.3411016949152542,0.36582098206084,0.3449801024148061,0.3385861593699268,0.3681902474178662,0.3411016949152542,0.3384052200196111,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_03:47:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.3430232558139535,0.3853151759536031,0.3518509271024415,0.3489009964775318,0.3715683894609181,0.3430232558139535,0.3370660316335658,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:47:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.3391472868217054,0.3678628898768836,0.364986061482427,0.3578046330710215,0.3519799130910339,0.3391472868217054,0.336834060349307,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-07_10:45:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.3464730290456431,0.3420015717656304,0.362969975144268,0.339833812139458,0.344268631945012,0.3464730290456431,0.3330947524747023,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-05_23:07:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.3423236514522821,0.3415050318568625,0.3456465326895751,0.3277440550428542,0.3525213479233842,0.3423236514522821,0.3308523503187699,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:39:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3630705394190871,0.3577757719389836,0.3749393279305914,0.3361058880734754,0.362837618219714,0.3630705394190871,0.3307291832305991,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:30:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3326271186440678,0.3585835186659357,0.341824046680237,0.3347295037841627,0.3601449024084249,0.3326271186440678,0.32998580678103506,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_08:15:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-08_07:22:15.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.3421633554083885,0.3358123640165887,0.3528744363526972,0.3309870598283776,0.3408160818359122,0.3421633554083885,0.3298348033856589,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_13:09:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.3333333333333333,0.3623612206068065,0.3483399242170611,0.3418003927146011,0.3483346735234996,0.3333333333333333,0.3271720423191525,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:36:09.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.3311258278145695,0.3524378799411506,0.3479886518473475,0.3412656054246741,0.3395089751040063,0.3311258278145695,0.3269337948592486,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_12:06:02.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.326271186440678,0.3641424731151584,0.3294169032860345,0.3235529012614636,0.3752422154656933,0.326271186440678,0.326404560987671,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_01:54:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.3236434108527132,0.412738135711078,0.3249566259545732,0.3322366733166806,0.3870980484606898,0.3236434108527132,0.3255360587237649,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:08:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.3275193798449612,0.3583539042440725,0.3424099060510589,0.3376753433767798,0.3469379924013938,0.3275193798449612,0.3248427527127297,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:32:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.3220338983050847,0.36167598404634,0.3244734564156366,0.3204423978967834,0.368043142853252,0.3220338983050847,0.3234175232446569,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_08:00:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-08_07:22:15.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.3340248962655601,0.3387367508514768,0.3497666698961429,0.3292956865544448,0.3399471329163955,0.3340248962655601,0.3232559010404581,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:44:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.3255813953488372,0.3776749688619955,0.3324607073882381,0.3321445655549419,0.3655279088246464,0.3255813953488372,0.3232052891418449,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:31:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.3399558498896247,0.3625462005027077,0.3416657959592742,0.3286627192595587,0.3573343154732464,0.3399558498896247,0.3229789881421593,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_09:53:21.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3283898305084746,0.3953027168700964,0.3411374527003226,0.3244354555141105,0.4083419434068681,0.3283898305084746,0.3228092438169216,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_04:41:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.3421633554083885,0.3399006903803983,0.3475099397382006,0.3272659277904933,0.3369963781963153,0.3421633554083885,0.3223461638301392,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:33:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.3360995850622407,0.3325511632389661,0.3471215029971092,0.320465631962856,0.3472336003193752,0.3360995850622407,0.3213487842554905,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:12:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3399558498896247,0.3188740625223931,0.3451131678305591,0.3225369671535397,0.3204007208343117,0.3399558498896247,0.3208789354933337,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:23:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.315891472868217,0.360454304316268,0.3239236274679639,0.3271535679992877,0.3502065762278595,0.315891472868217,0.318496547624629,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:04:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.3241525423728814,0.3581749870905861,0.3252382037032672,0.316420983616802,0.3621531456165263,0.3241525423728814,0.3165190100918312,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_01:14:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.3134657836644591,0.3752697879983497,0.3208305060478973,0.31900128081536,0.3806572219829723,0.3134657836644591,0.3160304112765474,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:49:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.3236434108527132,0.3471871796850574,0.3304377813467697,0.3254215229824573,0.3339308158897924,0.3236434108527132,0.3148468422152791,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:03:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.3197674418604651,0.3476161458892807,0.3270219075337698,0.3241168371229525,0.3352511965271382,0.3197674418604651,0.3145496477904099,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:01:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.3177966101694915,0.3323147786203715,0.3211499858314938,0.3147687481937514,0.3336085434844136,0.3177966101694915,0.3145017499808423,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_02:53:51.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.3311258278145695,0.3340857577935667,0.3302961571439832,0.3177687688087177,0.3222413504295731,0.3311258278145695,0.3132242790403491,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:46:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.3340248962655601,0.3077159531550596,0.3299401781277163,0.3046848113409926,0.318600430999109,0.3340248962655601,0.3125608545026536,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:56:02.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.3402489626556016,0.3120878128579367,0.349768838409467,0.3168549879150851,0.3102567517889062,0.3402489626556016,0.3123325365624157,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:39:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.3156779661016949,0.3616453561773301,0.3186955096064028,0.3105170526814073,0.3721446052928571,0.3156779661016949,0.312141186820691,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_01:48:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.3402489626556016,0.3157438598478442,0.3428303435865643,0.3104196397541566,0.3211945891526921,0.3402489626556016,0.3119312344470812,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:28:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.3236434108527132,0.381888490968114,0.3167481341203578,0.3185998018703767,0.3656912930312846,0.3236434108527132,0.3118084284529782,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:42:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.3319502074688796,0.3331729468975919,0.3477980463217807,0.3142813400857948,0.3446976824800811,0.3319502074688796,0.3096514290298958,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:56:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.3222958057395143,0.3336681633193986,0.3171919686593599,0.3080412567468537,0.3317003643911312,0.3222958057395143,0.3096253290600086,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_11:56:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.3267108167770419,0.3140088597873841,0.3302719281523629,0.309524650731498,0.3157956582791355,0.3267108167770419,0.3093243741211918,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:42:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.3207126948775056,0.3371406347048314,0.3149977641753957,0.3035584510743102,0.3213037709175262,0.3207126948775056,0.30918776147563,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:08:09.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.313953488372093,0.372791081322753,0.3258339019642358,0.325297397755144,0.3510864481437334,0.313953488372093,0.3091356839620759,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:37:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,False,val_loss,min,5,0.3111111111111111,0.3301859909994526,0.32878737423096,0.3232937944408532,0.3173743024098413,0.3111111111111111,0.3086763740641648,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_03:08:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,False,val_loss,min,5,0.3111111111111111,0.3317701456930163,0.3274777456481991,0.3211279865433661,0.320084068942187,0.3111111111111111,0.3080513493233216,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_04:00:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.3062015503875969,0.3703313220929193,0.3199898365358386,0.3234372292865051,0.3514285516446633,0.3062015503875969,0.3077944589073579,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:33:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.313953488372093,0.3462082329253714,0.3266770508062405,0.3187852827791935,0.3339582310219494,0.313953488372093,0.3068385368598658,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:11:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.3081395348837209,0.3711285012661267,0.326321105529579,0.3230358637159433,0.3561719334584217,0.3081395348837209,0.3065104442891364,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:10:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.3100775193798449,0.3872244141569084,0.3154133828598426,0.3152326565780039,0.3767729195799814,0.3100775193798449,0.306165676750829,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:42:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,False,val_loss,min,5,0.3145299145299145,0.3081611737048118,0.3299794834328315,0.3147323453219389,0.3037826561067265,0.3145299145299145,0.305271947131679,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_05:01:54.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,False,val_loss,min,5,0.3025641025641025,0.3312501702686752,0.3180806510703769,0.3211811086802622,0.3134286810170432,0.3025641025641025,0.3048785639500266,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32_2024-04-06_02:08:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.3134657836644591,0.3385553372238155,0.3226799790386747,0.3093890386270704,0.3383506141985842,0.3134657836644591,0.3045584465742511,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_11:16:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.3100775193798449,0.3558868337544808,0.3242676960396707,0.3162410253524764,0.3464250878067567,0.3100775193798449,0.3042831216532579,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:13:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.3112582781456953,0.3317929884741047,0.3196903036576949,0.3047029220969001,0.3359885003514704,0.3112582781456953,0.3025577984950498,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_11:52:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.3245033112582781,0.3255786986797758,0.3331140920271355,0.3076116920651449,0.3221122883385127,0.3245033112582781,0.3019828958950149,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_09:48:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.312015503875969,0.3848004232316962,0.3170661638973491,0.3102072722490797,0.3685128200586383,0.312015503875969,0.3017777159991467,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:30:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.313953488372093,0.371308643595116,0.3223447592301408,0.3092858665510343,0.364032272540603,0.313953488372093,0.2992598590554893,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_11:52:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.313953488372093,0.3419867291752373,0.3124487535728955,0.3041906120916218,0.3346776224252422,0.313953488372093,0.2992163861008503,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:45:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.3236514522821577,0.312712971120803,0.3289347059323129,0.3025146634997074,0.3106230966129794,0.3236514522821577,0.2990716589820158,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:26:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.3008474576271186,0.3439437636585605,0.3034630116778778,0.2960336729933451,0.3554019904877391,0.3008474576271186,0.2989636815903868,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_03:01:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.3072033898305085,0.348737311025929,0.310410578810997,0.2962057213642293,0.3543144370761053,0.3072033898305085,0.2973673236888716,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_01:08:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.3091286307053942,0.3077833388400086,0.3250489834879665,0.3004868776701265,0.3159533656002161,0.3091286307053942,0.2964963914917743,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:10:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.312015503875969,0.36894542198755,0.3086765046647265,0.3030354988341018,0.3533535419310423,0.312015503875969,0.2954815999404017,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:13:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.3100775193798449,0.3878321874778686,0.2886689623511201,0.2879498415983231,0.3779250708870084,0.3100775193798449,0.2951320660216607,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:35:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.3029045643153527,0.316767816502857,0.3080060981694428,0.2952377684961114,0.3197460762664065,0.3029045643153527,0.2941591490179483,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:42:58.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3068432671081678,0.3059437874410134,0.3091875998397737,0.2924711298481311,0.3077785654194085,0.3068432671081678,0.2930319466680792,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_13:12:14.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.3003875968992248,0.3924728265203027,0.3028269918256961,0.3039276671677067,0.3714439771530088,0.3003875968992248,0.2928418221162033,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:07:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,False,val_loss,min,5,0.2888888888888888,0.3189033325219136,0.3039046627814855,0.3035822266922774,0.3100258216408764,0.2888888888888888,0.2925274432732629,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128_2024-04-06_03:32:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.3091286307053942,0.3056371449013788,0.3164664320821561,0.2991585786547704,0.2983335751175129,0.3091286307053942,0.2923357964719976,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:54:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.3068432671081678,0.3179929025918924,0.2998218890610195,0.2851115901913313,0.3219912778269941,0.3068432671081678,0.2908285345391366,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:26:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.3024282560706401,0.3081761128439498,0.3107186312077616,0.2933058431337508,0.3060332731585486,0.3024282560706401,0.2899032424543321,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:58:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.3008298755186722,0.3052160461682375,0.3112406684428083,0.2889168962108416,0.3153476051247602,0.3008298755186722,0.289466084320922,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:05:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.2946058091286307,0.2988845455428185,0.3027309636366639,0.2884904658347728,0.3060008319095951,0.2946058091286307,0.2885664257871864,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:58:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.3049792531120332,0.3265048315599482,0.3335589902141374,0.292534715652253,0.339589734697063,0.3049792531120332,0.2884885391446367,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_00:00:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.2926356589147287,0.3475307190966953,0.3071199510501065,0.3019078813649847,0.3300586270805727,0.2926356589147287,0.2871362263019003,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:41:22.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.2868217054263566,0.3323790093436835,0.2904653422361728,0.2887296555851433,0.3283554645884843,0.2868217054263566,0.2864051459218981,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:01:02.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,False,val_loss,min,5,0.2905982905982906,0.3005000629147654,0.3023633843717859,0.2916951357355449,0.2966529819543747,0.2905982905982906,0.2853771025546361,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64_2024-04-06_04:37:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.2906976744186046,0.3436236144533892,0.2884494774107105,0.2884991581991276,0.3315431280261754,0.2906976744186046,0.2850944350504493,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:09:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.2939866369710467,0.2905643212165238,0.2939324106692528,0.2741937441067723,0.3113935533268536,0.2939866369710467,0.2846318649933963,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_00:38:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.3024282560706401,0.3014063577877505,0.3020924164402425,0.2839156071549851,0.3000853626264764,0.3024282560706401,0.2832566705804097,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_09:58:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,False,val_loss,min,5,0.2837606837606837,0.2918184352720883,0.2746166251374231,0.276612534352618,0.2918400663446182,0.2837606837606837,0.2822540210479289,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_03:46:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,False,val_loss,min,5,0.2871794871794871,0.2821188211274059,0.2848638421964348,0.2767292262116129,0.2866005584298267,0.2871794871794871,0.2809507331723704,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256_2024-04-06_05:16:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.2847682119205298,0.2885240611477896,0.2877564725934291,0.2790967271544419,0.2886451797107917,0.2847682119205298,0.277510590663343,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_13:06:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.2966804979253112,0.2884839360754692,0.3045965665878773,0.2780339021859239,0.289165172166492,0.2966804979253112,0.277062653559032,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:52:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.2863070539419087,0.2678323106639843,0.2831803760236037,0.2677557685164197,0.2831738478832865,0.2863070539419087,0.2769244766951415,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:06:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.2863070539419087,0.2919762402021479,0.2831817499405124,0.2696155672981437,0.2992577932845106,0.2863070539419087,0.2736509573264331,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:51:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.2958057395143488,0.3159368093529277,0.3097712854778071,0.2823531178784561,0.3109074054584249,0.2958057395143488,0.2726052804238068,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:44:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.2904564315352697,0.2739632788607229,0.284021156058711,0.2652409965641668,0.2804613435869111,0.2904564315352697,0.2713769443307574,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:41:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.2626931567328918,0.3214969814574616,0.2604763372698155,0.2666156504970363,0.3257978547556203,0.2626931567328918,0.2703323516642272,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:04:44.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.2891832229580574,0.3141240508979398,0.2909015843254973,0.2710317779519497,0.3114269682416294,0.2891832229580574,0.2700120655997927,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:49:39.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.2829457364341085,0.3097801293625933,0.2800288939472207,0.276033030365541,0.2950468785307519,0.2829457364341085,0.2697456893480101,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_09:41:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.2946058091286307,0.2755276720779691,0.2969633074115074,0.267819662002852,0.2815367571420361,0.2946058091286307,0.2692880125219193,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:42:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.2863070539419087,0.2798956156502596,0.2859158576368404,0.2625744282373368,0.2898183593901255,0.2863070539419087,0.2684730904697661,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:49:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.2863070539419087,0.2816105589227308,0.2941018783896331,0.2658521647200595,0.289546361614091,0.2863070539419087,0.2669675761912449,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:03:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.2957264957264957,0.2785170303429217,0.2493533418257526,0.2482406407737612,0.2813470940904402,0.2957264957264957,0.2637117855923294,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:10:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.2751937984496124,0.3072814522841363,0.2663639464381657,0.2634604389514493,0.3051135049230113,0.2751937984496124,0.2625433517725998,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_10:37:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.2803532008830022,0.2712764608186809,0.2710125965017269,0.2574783376757434,0.2714392349207266,0.2803532008830022,0.2618172062253434,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_11:13:13.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.267260579064588,0.2989590499876641,0.257885521155258,0.2452490530819023,0.3215240320469718,0.267260579064588,0.260077041119147,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:35:01.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.2803532008830022,0.2899367807204921,0.290311982703287,0.2633187048048315,0.2888898666481236,0.2803532008830022,0.2581229156669103,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:29:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.2605790645879732,0.2510307926300364,0.2571891658536395,0.2469095871034497,0.2673134702054901,0.2605790645879732,0.2572266204128856,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:53:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.2751937984496124,0.3181627060331417,0.2690812813957752,0.2589032934770754,0.3041598409544075,0.2751937984496124,0.2567518400804992,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:05:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.2759381898454746,0.2824888672306085,0.2785514284427327,0.2573399738513639,0.2801040235530717,0.2759381898454746,0.2546871668297957,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:54:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.2697095435684647,0.2650203076572767,0.2879271517947896,0.2579420084789544,0.2696157246387689,0.2697095435684647,0.2532649392320885,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:12:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.2869757174392936,0.2917845599629904,0.2962148720844372,0.254107788703242,0.2949303483575735,0.2869757174392936,0.2530578996621003,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:00:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.2693156732891832,0.2706616189241363,0.2710684504706243,0.249418998761436,0.2753715041482723,0.2693156732891832,0.2510294793196737,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:36:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.2655038759689923,0.356337327906977,0.253740304656158,0.2470595350018277,0.3417715710670025,0.2655038759689923,0.2502630730851606,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_08:01:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.282560706401766,0.2683457427456768,0.2951423717184587,0.2511681162499476,0.271488080556972,0.282560706401766,0.2487030678157711,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_11:11:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.2538975501113585,0.3012525153455245,0.2516620606489027,0.2401713336457097,0.3182746176385372,0.2538975501113585,0.2476719051138678,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_00:24:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.2888888888888888,0.2792971195471195,0.2374115430922706,0.2256789313008778,0.274862672939596,0.2888888888888888,0.2457998251436886,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:12:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.2472160356347438,0.2802316439925135,0.2510925261385788,0.2371537555270889,0.2985224611263151,0.2472160356347438,0.24379608796,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_22:25:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.2752136752136752,0.265026934881424,0.2369806402216394,0.2295632632834908,0.2628421725135228,0.2752136752136752,0.243718746077739,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:58:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.2923076923076923,0.2976190445953834,0.2307614309781492,0.2257996605363058,0.2781173733920219,0.2923076923076923,0.2427700782629082,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:24:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.2738589211618257,0.2347685992578085,0.2806196229466766,0.2434604827042485,0.2364418098646131,0.2738589211618257,0.2426611542737176,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:59:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.2561247216035635,0.2790394215249883,0.2414954937849675,0.2302711815679761,0.2897914074658853,0.2561247216035635,0.2420821454909696,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:29:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.2583518930957684,0.2788297109036078,0.26023559627507,0.2406931753313331,0.2761683363033796,0.2583518930957684,0.241799463555868,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_22:35:23.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.2786324786324786,0.2842927677540854,0.2286425755085746,0.2219562963531043,0.2864747712578447,0.2786324786324786,0.239532668570655,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:09:31.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.271523178807947,0.2671006960103808,0.2778335553335553,0.2396985294980035,0.2691715517057752,0.271523178807947,0.2379044009849919,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_10:51:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,35,0.282051282051282,0.2433265137663682,0.2284115994800979,0.2212492983858909,0.2455340208711066,0.282051282051282,0.2364880063193113,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:14:19.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.2360801781737193,0.2700205822577454,0.2385118200512937,0.2275591627305244,0.2835397484068289,0.2360801781737193,0.2332041810009862,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_00:33:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,20,0.242761692650334,0.2699204562858749,0.2403688010332746,0.2316670393951438,0.259575769061029,0.242761692650334,0.2314426729117079,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:28:05.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.2405345211581291,0.3040421649034078,0.2441673538449854,0.232059433153684,0.3003599731997753,0.2405345211581291,0.2311015260017614,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:26:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.282051282051282,0.3398076976023211,0.230467863968538,0.2195165592060417,0.3160307248662792,0.282051282051282,0.2303246178460722,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:40:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.2494432071269487,0.2621474845296497,0.2491836852231589,0.2284768390952764,0.2733099307724573,0.2494432071269487,0.22927913783249,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_00:28:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.2468879668049792,0.2310345938181111,0.2610059108657425,0.232522321278331,0.2319384315791032,0.2468879668049792,0.2277290014468672,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:11:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,35,0.2632478632478632,0.3380972074022793,0.2062512835216944,0.2138709142209739,0.3232802161636433,0.2632478632478632,0.2255198841219872,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:29:30.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,30,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.260485651214128,0.2467283044167081,0.2790527648679822,0.2312714957905067,0.250087497197789,0.260485651214128,0.2232646128318715,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_12:29:36.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.2405345211581291,0.2888868296086626,0.2423983246285877,0.2183592295088074,0.3005754460864563,0.2405345211581291,0.2225806562710055,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_22:59:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.2405345211581291,0.2518630555597729,0.242817127073706,0.217619976215709,0.2630201857873727,0.2405345211581291,0.2218084527777207,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:46:49.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.27008547008547,0.2877024341280534,0.2152391826522956,0.2058708494033014,0.2620344276448362,0.27008547008547,0.2208076310522143,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:55:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,25,0.2581196581196581,0.2615446595049742,0.2124197738147977,0.200935593102019,0.2574227040279607,0.2581196581196581,0.2197372587058194,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:56:07.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.2365145228215767,0.2445164356653438,0.2408582851507457,0.2179584159497928,0.2526031225868681,0.2365145228215767,0.2196747565196831,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:04:32.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.2360801781737193,0.2402381088821041,0.2447604004182951,0.2165384975349834,0.2532903455254216,0.2360801781737193,0.2193312530760597,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:54:28.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.2383073496659243,0.2257413648813905,0.2417077413327413,0.215342162516074,0.2383745556039485,0.2383073496659243,0.2168359812426783,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:52:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.252991452991453,0.222333770058458,0.2149616291556019,0.198505340861273,0.2319035933231683,0.252991452991453,0.2166398996403342,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:28:17.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,20,0.2338530066815144,0.2687358093975741,0.2355306048727101,0.2102247099058058,0.2812338588671617,0.2338530066815144,0.2163957587162875,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:24:50.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.2615384615384615,0.2155549497593706,0.2125481279556356,0.1920015207895875,0.2275315982605453,0.2615384615384615,0.2148189150172678,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:52:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.2461538461538461,0.2258642106923715,0.1953678648820839,0.1911410628889436,0.2294300543183106,0.2461538461538461,0.2147244785011092,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:43:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,64,64,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,30,0.2161016949152542,0.3178904219821415,0.2324836422640809,0.216224708481941,0.3138963610645791,0.2161016949152542,0.2134575090731273,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-08_02:00:38.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-07_20:29:04.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,25,0.2293986636971046,0.210121063659868,0.221179326764853,0.2014544913344648,0.2228431670943615,0.2293986636971046,0.2126570402799381,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:01:40.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.2338530066815144,0.2288402541179958,0.2336356769448875,0.2055709076251834,0.2404683257591486,0.2338530066815144,0.2125856803477533,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:02:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,20,0.2615384615384615,0.2099795824179517,0.2099491792791878,0.1846579026393698,0.2221654656972412,0.2615384615384615,0.2120631242216148,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:22:06.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,25,0.2405345211581291,0.2188567491284882,0.2364667211443527,0.1993846793530073,0.2369944068283372,0.2405345211581291,0.2101307137120387,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:30:12.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,20,0.27008547008547,0.2448591000451819,0.1906349248673102,0.1861348945059101,0.2367908119985176,0.27008547008547,0.2085646322350307,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:51:08.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.2365145228215767,0.2307946920786434,0.25348766657737,0.2123506239319206,0.2337007417124485,0.2365145228215767,0.2078497698949163,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_22:57:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,35,0.2338530066815144,0.2299505189475664,0.228931011483643,0.2032693663285492,0.2269688853729758,0.2338530066815144,0.2069403819491262,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:11:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.2182628062360802,0.2294402923939428,0.2259996747891484,0.2049296283415024,0.2385624808417294,0.2182628062360802,0.206077090842883,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:32:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,35,0.2581196581196581,0.1918454203156888,0.2011312610862695,0.1807541721527311,0.2021070323222923,0.2581196581196581,0.2053764334778827,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:58:41.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.220489977728285,0.2090631927917031,0.2236859376004113,0.2008175529270273,0.2196397181820542,0.220489977728285,0.2046555646719088,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:50:03.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,35,0.2358974358974359,0.2193778774062423,0.19867922477133,0.1944927490780346,0.2070410695091964,0.2358974358974359,0.2042407738452299,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:44:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,20,0.2581196581196581,0.2156501366785052,0.1824015674870938,0.1813813853945838,0.2160755733865618,0.2581196581196581,0.2035193360186024,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:54:00.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,10,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.2240663900414937,0.2179214887095072,0.2306389397336953,0.2027541695033582,0.2270089619921508,0.2240663900414937,0.2034950730027016,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-05_23:59:33.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.2547008547008547,0.2207153180534187,0.202135726897524,0.183291594170662,0.2207439861344103,0.2547008547008547,0.2024740700980523,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:53:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,128,True,val_loss,min,25,0.2512820512820513,0.2106636778032659,0.187373958054773,0.174069407319499,0.2125839829819958,0.2512820512820513,0.2018959206140942,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:41:43.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,30,0.2393162393162393,0.1996617459185367,0.2145411955605454,0.1949992245938943,0.1932362784552412,0.2393162393162393,0.2010843772276969,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:26:35.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,20,0.2376068376068376,0.2416176952547182,0.1927869937122034,0.1858850243908502,0.2317235559214609,0.2376068376068376,0.2009093173794929,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:22:16.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.2115812917594654,0.2110859373836878,0.2073789066683803,0.1918338803521333,0.2240025073246228,0.2115812917594654,0.2007523247898951,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:51:11.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,20,0.2393162393162393,0.2135673400218221,0.1827321805015303,0.1754769503303811,0.212705233122845,0.2393162393162393,0.1991756909109286,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:23:34.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,25,0.2461538461538461,0.2192628382516729,0.1696467458451753,0.1699786006220195,0.215165113373194,0.2461538461538461,0.197323578901705,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_05:24:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.2160356347438752,0.1973118520959553,0.2126339501142132,0.1901792071403837,0.2065831476112245,0.2160356347438752,0.1971487595666339,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:04:47.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.2376068376068376,0.2233667569848722,0.1659228401683834,0.1654839398058266,0.2283177955661441,0.2376068376068376,0.1952673408687941,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_02:59:42.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,30,0.2495726495726495,0.2426534387535099,0.1845802167245666,0.1790912444949242,0.2304387879402561,0.2495726495726495,0.1945476050694796,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:28:46.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,128,True,val_loss,min,30,0.2138084632516703,0.1993613059376674,0.2105921261973893,0.1842180175342322,0.2092341960799337,0.2138084632516703,0.1925444131825635,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_128__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:32:26.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,25,0.2683760683760683,0.2060340402839834,0.2057231830102348,0.1737025032940006,0.1959127457879191,0.2683760683760683,0.1913697166688636,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:25:15.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.229059829059829,0.229657375268948,0.1671307619234189,0.1650055466254265,0.2310921460371588,0.229059829059829,0.1905511588358089,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:55:37.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,20,0.2115812917594654,0.1696473927642406,0.2001316634145581,0.1723766589584465,0.1855538339225518,0.2115812917594654,0.1866735472713882,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_22:21:24.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,64,True,val_loss,min,30,0.2461538461538461,0.1631322722876872,0.1892824938690813,0.1577936663710794,0.169832086735653,0.2461538461538461,0.1809914376661252,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:26:45.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,256,True,val_loss,min,35,0.198218262806236,0.177858240896558,0.1920732532574638,0.1691984641488591,0.1904296171777411,0.198218262806236,0.1780255211725128,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:57:10.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,30,0.2071269487750557,0.2265567222093971,0.2146857652581336,0.1739558160234191,0.2345105335344339,0.2071269487750557,0.1736960652506072,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:08:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,35,0.2341880341880342,0.1971610665451245,0.1603397116156404,0.1481416631339747,0.1899993406124955,0.2341880341880342,0.1692821295158338,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:03:48.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,25,0.1959910913140311,0.1513573701010935,0.1913138394256815,0.1582746151704688,0.1648869048121732,0.1959910913140311,0.1689307138804764,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_23:48:53.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,64,True,val_loss,min,25,0.1848552338530066,0.1696834313473753,0.1805801569288411,0.1560465441936192,0.1771957223580541,0.1848552338530066,0.1626157041299888,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_64__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-07_01:05:20.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,40,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,32,True,val_loss,min,30,0.1692650334075723,0.1800382296320511,0.1713820767439188,0.1563850683222651,0.1882746327688813,0.1692650334075723,0.1594714250171997,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_22:30:18.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-06_17:43:13.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,False,200,256,True,val_loss,min,30,0.2307692307692307,0.1373331140579202,0.1563391812865497,0.1334136720891838,0.1426762897872021,0.2307692307692307,0.159415120685023,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_256__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_03:56:59.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
20,32,32,20,42,HARM - ConvLSTM,softmax,categorical_crossentropy,0.005,True,200,32,True,val_loss,min,35,0.2393162393162393,0.1573916652538672,0.1518879142300195,0.1211858835834312,0.1550127271970692,0.2393162393162393,0.1529307225849539,/Human_Activity_Video_Recognition/data/output/models/HMDB/human_activity_recognition_model_20_classes_adam_0_005__epochs_200__batch_size_32__early_stopping_monitor_val_loss_mode_min_patience_15_2024-04-06_04:32:56.keras,/Human_Activity_Video_Recognition/data/output/logs/model_evaluation/evaluation_log_2024-04-05_22:16:40.log
